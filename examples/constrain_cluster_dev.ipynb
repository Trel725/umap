{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dev-code for umap/constrain_clust.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We were asked for a clusterer.\n",
    "Every time the cluster membership changes, you create a clustering function.\n",
    "\n",
    "-API **mk_clusters(clusters, springs, *, mindist=None, mults=None, wm=None)**\n",
    "  - input as list-of-lists `clusters[c][i]`: (i) cluster(`c`=0,1,...), (ii) points (indices `idx`) in cluster.\n",
    "    - also internally remember map of index to clusters: `clusts[idx] = list-of-cluster(`c`)`\n",
    "    - also internally calculate cluster size `cl_n[c]`\n",
    "    - and cluster average position `cl_avg[c]`\n",
    "    - opt. store both as numpy sparse matrix + sparse transpose ?\n",
    "  - input spring force `springs[c]` and opt. learning rate lr=1.0\n",
    "  - input optional de-neighboring `mults[c]` (default 1.0) and modify umap weight matrix `wm`\n",
    "  - input optional mindist for short-range cluster repulsive force (Morse function variant?)\n",
    "  - output jit func (`idx`, `pts`)\n",
    "    - for `c` in `clusts[idx]`:  # all clusters c of idx\n",
    "      - `delta` of pt moved toward `cl_avg[c]` with `springs[c]`\n",
    "      - quick-update `cl_avg[c]` by `(delta / cl_n[c])`\n",
    "      - opt. every 100'th call, recalculate exact cluster averages instead of `delta`-update\n",
    "      - opt. short-range repulsion to other neighbors of `idx` in cluster `c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=-1.00 y1=smoothstep(x,0,1) 0.0000 type(y1)=<class 'float'>\n",
      "x=-0.80 y1=smoothstep(x,0,1) 0.0000 type(y1)=<class 'float'>\n",
      "x=-0.60 y1=smoothstep(x,0,1) 0.0000 type(y1)=<class 'float'>\n",
      "x=-0.40 y1=smoothstep(x,0,1) 0.0000 type(y1)=<class 'float'>\n",
      "x=-0.20 y1=smoothstep(x,0,1) 0.0000 type(y1)=<class 'float'>\n",
      "x=0.00 y1=smoothstep(x,0,1) 0.0000 type(y1)=<class 'float'>\n",
      "x=0.20 y1=smoothstep(x,0,1) 0.1040 type(y1)=<class 'float'>\n",
      "x=0.40 y1=smoothstep(x,0,1) 0.3520 type(y1)=<class 'float'>\n",
      "x=0.60 y1=smoothstep(x,0,1) 0.6480 type(y1)=<class 'float'>\n",
      "x=0.80 y1=smoothstep(x,0,1) 0.8960 type(y1)=<class 'float'>\n",
      "x=1.00 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=1.20 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=1.40 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=1.60 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=1.80 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=2.00 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=2.20 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=2.40 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=2.60 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=2.80 y1=smoothstep(x,0,1) 1.0000 type(y1)=<class 'float'>\n",
      "x=-1.00 y2=smoothstep(x,1,0)=1.00 type(y2)=<class 'float'>\n",
      "x=-0.80 y2=smoothstep(x,1,0)=1.00 type(y2)=<class 'float'>\n",
      "x=-0.60 y2=smoothstep(x,1,0)=1.00 type(y2)=<class 'float'>\n",
      "x=-0.40 y2=smoothstep(x,1,0)=1.00 type(y2)=<class 'float'>\n",
      "x=-0.20 y2=smoothstep(x,1,0)=1.00 type(y2)=<class 'float'>\n",
      "x=0.00 y2=smoothstep(x,1,0)=1.00 type(y2)=<class 'float'>\n",
      "x=0.20 y2=smoothstep(x,1,0)=0.90 type(y2)=<class 'float'>\n",
      "x=0.40 y2=smoothstep(x,1,0)=0.65 type(y2)=<class 'float'>\n",
      "x=0.60 y2=smoothstep(x,1,0)=0.35 type(y2)=<class 'float'>\n",
      "x=0.80 y2=smoothstep(x,1,0)=0.10 type(y2)=<class 'float'>\n",
      "x=1.00 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=1.20 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=1.40 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=1.60 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=1.80 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=2.00 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=2.20 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=2.40 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=2.60 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n",
      "x=2.80 y2=smoothstep(x,1,0)=0.00 type(y2)=<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "@numba.njit() #[\"f8(f4,f8,f8)\",\"f8(f8,f8,f8)\"])\n",
    "def smoothstep(x, edge0, edge1):\n",
    "    \"\"\" smoothstep smoothly interpolates between 0 and 1\n",
    "        as x transitions from edge0 to edge1.\n",
    "\n",
    "    pre-condition edge0 != edge1\n",
    "    \n",
    "    This is useful in cases where a threshold function with a smooth transition is desired.\n",
    "    smoothstep is equivalent to:\n",
    "    ```\n",
    "    genType t;  /* Or genDType t; */\n",
    "    t = clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0);\n",
    "    return t * t * (3.0 - 2.0 * t);\n",
    "    ```\n",
    "    \n",
    "    \"\"\"\n",
    "    t = min(max( float(x-edge0)/float(edge1-edge0), 0.0), 1.0)\n",
    "    return t * t * (3.0 - 2.0*t)\n",
    "\n",
    "for i in range(20):\n",
    "    x = (i-5) * 0.2\n",
    "    y1 = smoothstep(x,0.0,1.0)\n",
    "    print(f\"{x=:.2f} y1=smoothstep(x,0,1) {y1:.4f} {type(y1)=}\")\n",
    "for i in range(20):\n",
    "    x = (i-5) * 0.2\n",
    "    y2 = smoothstep(x,1.0,0.0)\n",
    "    print(f\"{x=:.2f} y2=smoothstep(x,1,0)={y2:.2f} {type(y2)=}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#\n",
    "# Here I put mv = lr * spring.   This changed physics has 'spring'\n",
    "# being a CONSTANT FORCE, rather than increasing as the spring is\n",
    "# extended.\n",
    "#\n",
    "def spring_mv_v0(pt, target, spring, lr=1.0, mindist=0.0, *, verbose=0):\n",
    "    \"\"\" spring force for time lr moves vector pt toward target without\n",
    "        overshoot, stopping mindist away.\n",
    "        \n",
    "        return the delta vector (all inputs const)\n",
    "    \"\"\"\n",
    "    # springs -> force gradient -> non-overshooting 'delta' movement\n",
    "    vec = target - pt      # vector toward cluster center\n",
    "    vecnorm = np.linalg.norm(vec)\n",
    "    #grad = np_springs[c] * vecnorm\n",
    "    ## Let's make the spring force never over-shoot\n",
    "    ##   v.0: by simply capping movement to \"90% of the way to cluster avg\"\n",
    "    #pct_move = min(0.9, (lr * grad)/vecnorm)\n",
    "    #delta = vec * pct_move\n",
    "    #\n",
    "    # --- now add mindist ---\n",
    "    #      \n",
    "    #      P-------------------|---A  P=pts[idx], A=cl_avg\n",
    "    # PA = vecnorm             ^\n",
    "    #      0          (vecnorm - mindist)\n",
    "    #\n",
    "    bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "    #frac_bar = bar / vecnorm          # max move fraction along vec\n",
    "    # 'lr' ~ \"time the force acts\", converting force into a distance\n",
    "    mv = lr * spring                  # force move dist (possibly overshoots)\n",
    "    # at mv==bar, we should have vec+delta stop mindist from cl_avg\n",
    "    #             begin with no 'underhoot'\n",
    "    frac_mv = min(mv, bar) / vecnorm\n",
    "    delta = frac_mv * vec\n",
    "    # pt' = pt + delta   =  pt + frac_mv*(target-pt)\n",
    "    #                    =  (1-frac_mv)*pt + frac_mv*target\n",
    "    if verbose>0:\n",
    "        print(f\" mv={100.*frac_mv:.2f}%\")\n",
    "    if verbose>1:\n",
    "        print(f\" {vec=}\")\n",
    "        print(f\" {vecnorm=} {mindist=}\")\n",
    "        print(f\" {bar=}\")\n",
    "        print(f\" {mv=}\")\n",
    "        print(f\" {frac_mv=}\")\n",
    "        print(f\" {delta=}\")\n",
    "    return delta\n",
    "\n",
    "nfail = 0\n",
    "def test_mv(pt, target, spring=1.0, lr=1.0, mindist=0.0, *, gives=None):\n",
    "    global nfail\n",
    "    delta = spring_mv_v0(pt,target,spring, lr, mindist)\n",
    "    if not np.allclose(delta, gives):\n",
    "        nfail += 1\n",
    "        delta = spring_mv_v0(pt,target,spring, lr, mindist, verbose=2)\n",
    "        print(f\"Failed: spring_mv_v0({pt},{target}, {spring},{lr}, {mindist}) ~= {gives}\")\n",
    "        print(f\"        spring_mv_v0 --> {delta}\")\n",
    "        print(f\"               EXPECTED: {gives}\")\n",
    "        print(f\"            discrepancy: {gives-delta}\")\n",
    "    return\n",
    "\n",
    "print(*(1,2,3))\n",
    "test_mv(0.0,10.0, 10.0,1.0, 0.0, gives=10.0)\n",
    "test_mv(0.0,10.0, 10.0,1.0, 1.0, gives=9.0)\n",
    "test_mv(0.0,10.0, 10.0,1.0, 9.0, gives=1.0)\n",
    "test_mv(0.0,10.0, 10.0,1.0, 10.0, gives=0.0)\n",
    "test_mv(0.0,10.0, 10.0,1.0, 11.0, gives=0.0)\n",
    "eps = 1e-3\n",
    "test_mv(0.0,10.0, 10+eps,1.0, 0.0, gives=10.0)\n",
    "test_mv(0.0,10.0, 10-eps,1.0, 0.0, gives=10-eps)\n",
    "test_mv(0.0,10.0, 10.0,1+eps, 0.0, gives=10.0)\n",
    "test_mv(0.0,10.0, 10.0,1-eps, 0.0, gives=10*(1-eps))\n",
    "test_mv(0.0,10.0, 10.0,1.0, 10.0-eps, gives=eps)\n",
    "test_mv(0.0,10.0, 10.0,1.0, 10.0+eps, gives=0.0)\n",
    "test_mv(0.0,10+eps, 10.0,1.0, 0.0, gives=10)\n",
    "test_mv(0.0,10+eps, 10.0,1.0, eps, gives=10)\n",
    "test_mv(0.0,10, 10.0,1.0, eps, gives=10-eps)\n",
    "\n",
    "test_mv(1.0,10.0, 10.0,1.0, 0.0, gives=9.0)\n",
    "test_mv(1.0,10.0, 10.0,1.0, 1.0, gives=8.0)\n",
    "test_mv(0.0,-10.0, 10.0,1.0, 0.0, gives=-10.0)\n",
    "test_mv(0.0,-10.0, 10.0,1.0, 1.0, gives=-9.0)\n",
    "test_mv(10.0,-10.0, 20.0,1.0, 0.0, gives=-20.0)\n",
    "test_mv(10.0,-10.0, 20.0,1.0, 1.0, gives=-19.0)\n",
    "\n",
    "print(\"Goodbye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "Goodbye\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# spring force is 'spring * extension'  (normal physics)\n",
    "#\n",
    "# So a spring constant of 1.0 applied for exactly 1.0 seconds\n",
    "# will move you from wherever exactly to spring equilibrium.\n",
    "#\n",
    "# Here 'lr' plays role of time, while 'mindist' applies a radius\n",
    "# to the target position.\n",
    "# I.e., spring=lr=1.0 would move towards target, but stop mindist away.\n",
    "#\n",
    "def spring_mv_v0(pt, target, spring, lr=1.0, mindist=0.0, *, verbose=0):\n",
    "    \"\"\" spring force for time lr moves vector pt toward target without\n",
    "        overshoot, stopping mindist away.\n",
    "        \n",
    "        return the delta vector (all inputs const)\n",
    "    \"\"\"\n",
    "    # springs -> force gradient -> non-overshooting 'delta' movement\n",
    "    vec = target - pt      # vector toward cluster center\n",
    "    vecnorm = np.linalg.norm(vec)\n",
    "    #grad = np_springs[c] * vecnorm\n",
    "    ## Let's make the spring force never over-shoot\n",
    "    ##   v.0: by simply capping movement to \"90% of the way to cluster avg\"\n",
    "    #pct_move = min(0.9, (lr * grad)/vecnorm)\n",
    "    #delta = vec * pct_move\n",
    "    #\n",
    "    # --- now add mindist ---\n",
    "    #      \n",
    "    #      P-------------------|---A  P=pts[idx], A=cl_avg\n",
    "    # PA = vecnorm             ^\n",
    "    #      0          (vecnorm - mindist)\n",
    "    #\n",
    "    bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "    #frac_bar = bar / vecnorm          # max move fraction along vec\n",
    "    # 'lr' ~ \"time the force acts\", converting force into a distance\n",
    "    mv = lr * bar * spring                  # force move dist (possibly overshoots)\n",
    "    # at mv==bar, we should have vec+delta stop mindist from cl_avg\n",
    "    #             begin with no 'underhoot'\n",
    "    frac_mv = min(mv, bar) / vecnorm\n",
    "    delta = frac_mv * vec\n",
    "    # pt' = pt + delta   =  pt + frac_mv*(target-pt)\n",
    "    #                    =  (1-frac_mv)*pt + frac_mv*target\n",
    "    if verbose>0:\n",
    "        print(f\" mv={100.*frac_mv:.2f}%\")\n",
    "    if verbose>1:\n",
    "        print(f\" {vec=}\")\n",
    "        print(f\" {vecnorm=} {mindist=}\")\n",
    "        print(f\" {bar=}\")\n",
    "        print(f\" {mv=}\")\n",
    "        print(f\" {frac_mv=}\")\n",
    "        print(f\" {delta=}\")\n",
    "    return delta\n",
    "\n",
    "# Equivalent terse version\n",
    "def spring_mv_v0_plain_dev(pt, target, spring, lr=1.0, mindist=0.0):\n",
    "    vec = target - pt      # vector toward cluster center\n",
    "    vecnorm = np.linalg.norm(vec)\n",
    "    if mindist > 0.0:\n",
    "        bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "        #mv = lr * bar * spring                  # force move dist (possibly overshoots)\n",
    "        #frac_mv = min(mv, bar) / vecnorm\n",
    "        #delta = frac_mv * vec\n",
    "        # equiv.\n",
    "        #delta = (min(lr * bar * spring, bar) / vecnorm) * vec\n",
    "        # or\n",
    "        delta = (min(lr * spring, 1.0) * bar / vecnorm) * vec\n",
    "        #\n",
    "        # or\n",
    "        #delta = (min(lr * spring, 1.0) * max(vecnorm - mindist, 0.0) / vecnorm) * vec\n",
    "        # or\n",
    "        #delta = (min(lr * spring, 1.0) * max(1.0 - mindist/vecnorm), 0.0) * vec\n",
    "        #  vecnorm does not \"cancel out\"\n",
    "    else: # mindist == 0.0\n",
    "        #bar = vecnorm\n",
    "        #mv = lr * bar * spring\n",
    "        #frac_mv = min(mv, bar) / vecnorm\n",
    "        #delta = frac_mv * vec\n",
    "        # equiv.\n",
    "        #delta = (min(vecnorm, lr * vecnorm * spring) / vecnorm) * vec\n",
    "        # or\n",
    "        delta = min(1.0, lr*spring) * vec\n",
    "        # Notice that vecnorm \"cancels out\" when mindist==0.0\n",
    "    return delta\n",
    "\n",
    "def spring_mv_v0_plain(pt, target, spring, lr=1.0, mindist=0.0):\n",
    "    vec = target - pt      # vector toward cluster center\n",
    "    if mindist > 0.0:\n",
    "        vecnorm = np.linalg.norm(vec)\n",
    "        bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "        #delta = (min(lr * spring, 1.0) * bar / vecnorm) * vec\n",
    "        delta = (min(bar, bar * lr * spring) / vecnorm) * vec\n",
    "    else: # mindist == 0.0\n",
    "        delta = min(1.0, lr*spring) * vec\n",
    "    return delta\n",
    "\n",
    "\n",
    "nfail = 0\n",
    "def test_mv(pt, target, spring=1.0, lr=1.0, mindist=0.0, *, gives=None):\n",
    "    global nfail\n",
    "    delta = spring_mv_v0(pt,target,spring, lr, mindist)\n",
    "    if not np.allclose(delta, gives):\n",
    "        nfail += 1\n",
    "        delta = spring_mv_v0(pt,target,spring, lr, mindist, verbose=2)\n",
    "        print(f\"Failed: spring_mv_v0({pt},{target}, {spring},{lr}, {mindist}) ~= {gives}\")\n",
    "        print(f\"        spring_mv_v0 --> {delta}\")\n",
    "        print(f\"               EXPECTED: {gives}\")\n",
    "        print(f\"            discrepancy: {gives-delta}\")\n",
    "    delta_plain = spring_mv_v0_plain(pt, target, spring, lr, mindist)\n",
    "    if not np.allclose(delta_plain, gives):\n",
    "        nfail += 1\n",
    "        #delta = spring_mv_v0(pt,target,spring, lr, mindist, verbose=2)\n",
    "        print(f\"Failed: spring_mv_v0_plain({pt},{target}, {spring},{lr}, {mindist}) ~= {gives}\")\n",
    "        print(f\"        spring_mv_v0_plain --> {delta_plain}\")\n",
    "        print(f\"                  EXPECTED: {gives}\")\n",
    "        print(f\"               discrepancy: {gives-delta_plain}\")\n",
    "    return\n",
    "\n",
    "print(*(1,2,3))\n",
    "test_mv(0.0,10.0, 1.0,1.0, 0.0, gives=10.0)\n",
    "test_mv(0.0,10.0, 1.0,1.0, 1.0, gives=9.0)\n",
    "test_mv(0.0,10.0, 1.0,1.0, 9.0, gives=1.0)\n",
    "test_mv(0.0,10.0, 1.0,1.0, 10.0, gives=0.0)\n",
    "test_mv(0.0,10.0, 1.0,1.0, 11.0, gives=0.0)\n",
    "eps = 1e-3\n",
    "test_mv(0.0,10.0, 1+eps,1.0, 0.0, gives=10.0)\n",
    "test_mv(0.0,10.0, 1-eps,1.0, 0.0, gives=10*(1-eps))\n",
    "test_mv(0.0,10.0, 1.0,1+eps, 0.0, gives=10.0)\n",
    "test_mv(0.0,10.0, 1.0,1-eps, 0.0, gives=10*(1-eps))\n",
    "test_mv(0.0,10.0, 1.0,1.0, 10.0-eps, gives=eps)\n",
    "test_mv(0.0,10.0, 1.0,1.0, 10.0+eps, gives=0.0)\n",
    "test_mv(0.0,10+eps, 1.0,1.0, 0.0, gives=10+eps)\n",
    "test_mv(0.0,10+eps, 1.0,1.0, eps, gives=10)\n",
    "test_mv(0.0,10, 1.0,1.0, eps, gives=10-eps)\n",
    "\n",
    "test_mv(1.0,10.0, 1.0,1.0, 0.0, gives=9.0)\n",
    "test_mv(1.0,10.0, 1.0,1.0, 1.0, gives=8.0)\n",
    "test_mv(0.0,-10.0, 1.0,1.0, 0.0, gives=-10.0)\n",
    "test_mv(0.0,-10.0, 1.0,1.0, 1.0, gives=-9.0)\n",
    "test_mv(10.0,-10.0, 1.0,1.0, 0.0, gives=-20.0)\n",
    "test_mv(10.0,-10.0, 1.0,1.0, 1.0, gives=-19.0)\n",
    "\n",
    "print(\"Goodbye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's demo python clustering internals (debug version)\n",
      "idx=0 pt0=array([0., 0.], dtype=float32) --> pts[idx,:]=array([0., 0.], dtype=float32)\n",
      "\n",
      "push pt 1 towards single cluster center 0\n",
      "cl_avg=array([2., 1.], dtype=float32)\n",
      "pt 1 [1. 1.] --> newpos [1.64 1.  ]\n",
      "cluster 0 : cl_avg_new=array([2.2133334, 1.       ], dtype=float32)\n",
      "idx=1 pt0=array([1., 1.], dtype=float32) --> pts[idx,:]=array([1.64, 1.  ], dtype=float32)\n",
      "\n",
      "push pt 2 towards cluster centers [0 1]\n",
      "eqm_pos=array([4.2038097, 1.       ], dtype=float32)\n",
      "pt 2 [2. 2.] --> newpos [4.2038097 1.       ]\n",
      "final pts[idx,:]=array([4.2038097, 1.       ], dtype=float32)\n",
      "idx=2 pt0=array([2., 2.], dtype=float32) --> pts[idx,:]=array([4.2038097, 1.       ], dtype=float32)\n",
      "\n",
      "push pt 3 towards single cluster center 0\n",
      "cl_avg=array([2.9479363, 0.6666667], dtype=float32)\n",
      "pt 3 [3. 0.] --> newpos [2.9708064  0.37381905]\n",
      "cluster 0 : cl_avg_new=array([2.938205  , 0.79127306], dtype=float32)\n",
      "idx=3 pt0=array([3., 0.], dtype=float32) --> pts[idx,:]=array([2.9708064 , 0.37381905], dtype=float32)\n",
      "idx=4 pt0=array([4., 1.], dtype=float32) --> pts[idx,:]=array([4., 1.], dtype=float32)\n",
      "idx=5 pt0=array([5., 2.], dtype=float32) --> pts[idx,:]=array([5., 2.], dtype=float32)\n",
      "\n",
      "push pt 6 towards single cluster center 1\n",
      "cl_avg=array([5.7346034, 0.6666667], dtype=float32)\n",
      "pt 6 [6. 0.] --> newpos [5.808576  0.4808495]\n",
      "cluster 1 : cl_avg_new=array([5.6707954 , 0.82694983], dtype=float32)\n",
      "idx=6 pt0=array([6., 0.], dtype=float32) --> pts[idx,:]=array([5.808576 , 0.4808495], dtype=float32)\n",
      "\n",
      "push pt 7 towards single cluster center 1\n",
      "cl_avg=array([5.6707954 , 0.82694983], dtype=float32)\n",
      "pt 7 [7. 1.] --> newpos [5.8691216 0.8527701]\n",
      "cluster 1 : cl_avg_new=array([5.293836 , 0.7778732], dtype=float32)\n",
      "idx=7 pt0=array([7., 1.], dtype=float32) --> pts[idx,:]=array([5.8691216, 0.8527701], dtype=float32)\n",
      "final positions (one epoch)\n",
      "i=0 pt = [0. 0.]\n",
      "i=1 pt = [1.64 1.  ]\n",
      "i=2 pt = [4.2038097 1.       ]\n",
      "i=3 pt = [2.9708064  0.37381905]\n",
      "i=4 pt = [4. 1.]\n",
      "i=5 pt = [5. 2.]\n",
      "i=6 pt = [5.808576  0.4808495]\n",
      "i=7 pt = [5.8691216 0.8527701]\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's demo python clustering internals (debug version)\")\n",
    "#\n",
    "# --------------------- Inputs -----------------\n",
    "#\n",
    "n_samples = 8\n",
    "cluster_lists = [[1,2,3], [2,7,6]]\n",
    "#           avg    2.0      5.0\n",
    "# each of the 2 clusters has a spring constant\n",
    "springs = np.array([0.8, 2.0])\n",
    "lr = 1.0   # learning rate (gradient multiplier) for spring forces\n",
    "\n",
    "pts = np.ndarray((n_samples,2), dtype=np.float32)\n",
    "for i in range(n_samples):\n",
    "    pts[i,:] = (float(i),float(i%3))\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# ---------------------- Functions --------------\n",
    "#\n",
    "def do_clustering_ipts(idx, pts, cluster_lists, springs, *, lr=1.0, mindist=0.01):\n",
    "    assert len(pts.shape) == 2\n",
    "    n_samples = pts.shape[0]\n",
    "    n_clust = len(cluster_lists)\n",
    "    assert n_clust > 0\n",
    "    assert len(springs) == len(cluster_lists)\n",
    "    np_cluster_lists = [np.array(clist,np.int32) for clist in cluster_lists]\n",
    "    np_springs = np.array(springs)\n",
    "    #\n",
    "    # cluster membership as bool array[cluster index][point index]\n",
    "    #\n",
    "    clusters = np.full((n_clust, n_samples), False, dtype=bool)\n",
    "    for (c,members) in enumerate(cluster_lists):\n",
    "        for m in members:\n",
    "            clusters[c][m] = True\n",
    "    \n",
    "    #print(f\"{clusters=}\")\n",
    "    verbose=0\n",
    "    if verbose>0: print(f\"{clusters[:,idx]=}\")\n",
    "    idx_in = clusters[:,idx]\n",
    "    #idx_in = np.equal( clusters[:,idx], True )\n",
    "    #print(f\"{idx=} in clusters {idx_in=}\")\n",
    "    #idx_cl = np.argwhere(idx_in) # size n_nonzero x idx_in_size ?\n",
    "    idx_cl = np.argwhere(idx_in).flatten()\n",
    "    if verbose>0: print(f\"{idx_cl=}\")\n",
    "    #\n",
    "    verbose=1\n",
    "    if len(idx_cl) < 1:\n",
    "        return\n",
    "\n",
    "    elif len(idx_cl) == 1:\n",
    "        # Separate out an easy case (idx in single cluster)\n",
    "        c = idx_cl[0]\n",
    "        if verbose>0: print(\"\\npush pt\",idx,\"towards single cluster center\",c)\n",
    "        #cluster_pts0 = np.argwhere(clusters[c,:]).flatten()\n",
    "        #print(f\"{cluster_pts0=}\")\n",
    "        #cluster_pts  = cluster_lists[c]\n",
    "        cluster_pts  = np_cluster_lists[c] # perhaps faster/vectorizable\n",
    "        if len(cluster_pts) <= 1:\n",
    "            print(\"noop: cluster empty or of size 1\")\n",
    "            return\n",
    "        if verbose>1: print(f\"{cluster_pts=}\")\n",
    "\n",
    "        # cl_avg ~ cluster center\n",
    "        # cleverer version:\n",
    "        cl_avg = np.mean(pts[cluster_pts,:], axis=0)\n",
    "        if verbose>0: print(f\"{cl_avg=}\")\n",
    "        if True: # long-handed\n",
    "            cl_avg0 = np.zeros((pts.shape[1]), dtype=np.float32)\n",
    "            for pt in cluster_pts:\n",
    "                cl_avg0 += pts[pt]\n",
    "            assert len(cluster_pts) > 1\n",
    "            cl_avg0 /= len(cluster_pts)\n",
    "            #if verbose>0: print(f\"{cl_avg0=}\")\n",
    "            assert np.allclose(cl_avg, cl_avg0)\n",
    "\n",
    "\n",
    "        # springs -> force gradient -> non-overshooting 'delta' movement\n",
    "        if False: # v.0\n",
    "            # springs -> force gradient -> non-overshooting 'delta' movement\n",
    "            vec = cl_avg - pts[idx]      # vector toward cluster center\n",
    "            vecnorm = np.linalg.norm(vec)\n",
    "            #grad = np_springs[c] * vecnorm\n",
    "            ## Let's make the spring force never over-shoot\n",
    "            ##   v.0: by simply capping movement to \"90% of the way to cluster avg\"\n",
    "            #pct_move = min(0.9, (lr * grad)/vecnorm)\n",
    "            #delta = vec * pct_move\n",
    "            #\n",
    "            # --- now add mindist ---\n",
    "            #      \n",
    "            #      P-------------------|---A  P=pts[idx], A=cl_avg\n",
    "            # PA = vecnorm             ^\n",
    "            #      0          (vecnorm - mindist)\n",
    "            #\n",
    "            bar = max(vecnorm - mindist, 0.0)\n",
    "            # 'lr' ~ \"time the force acts\", converting force into a distance\n",
    "            mv = lr * bar * np.springs[c]     # force move dist (possibly overshoots)\n",
    "            # at mv==bar, we should have vec+delta stop mindist from cl_avg\n",
    "            #             begin with no 'underhoot'\n",
    "            #frac_bar = bar / vecnorm # max move (dist along vec/vecnorm)\n",
    "            frac_mv = min(mv, frac_bar) / vecnorm\n",
    "            delta = vecbar * frac_mv\n",
    "        elif True:\n",
    "            delta = spring_mv_v0(pts[idx], cl_avg, springs[c], lr, mindist)\n",
    "        else:\n",
    "            # EXPERIMENTAL (can we \"smooth\" over the discontinuities)\n",
    "            vec = cl_avg - pts[idx]      # vector toward cluster center\n",
    "            vecnorm = np.linalg.norm(vec)\n",
    "            if vecnorm <= mindist: # no-op - pt is already within mindist of cl_avg\n",
    "                pct_move = 0.0\n",
    "                delta = vec * 0.0\n",
    "            else:\n",
    "                grad = np_springs[c] * vecnorm\n",
    "                gradnorm = lr * grad\n",
    "                # Let's make the spring force never over-shoot\n",
    "                #   v.0: by simply capping movement to \"90% of the way to cluster avg\"\n",
    "                pct_move0 = min(0.9, lr * grad)\n",
    "                #delta = vec * pct_move\n",
    "                #   v.1: mindist  lr*grad *= fn going from 0.0 to 1.0 as\n",
    "                #                         lr*grad goes from vecnorm-0.5*mindist to vecnorm-mindist\n",
    "                edge0 = max(vecnorm - 2*mindist, 0.0)\n",
    "                edge1 = vecnorm - mindist\n",
    "                if gradnorm <= edge0:\n",
    "                    pct_move = 1.0\n",
    "                else:\n",
    "                    mvlen = edge0 + (edge1-edge0) * smoothstep( gradnorm, edge0, edge1 )\n",
    "                    print(f\"{mvlen=}\")\n",
    "                    pct_move = (mvlen / vecnorm)\n",
    "                print(f\"{lr*grad=:.4f} {edge0=:.4f} {edge1=:.4f}\")\n",
    "                print(f\"{mindist=} pct_move v.0 {int(pct_move0*100.):.2f}% v.1 {int(pct_move*100.):.2f}\") \n",
    "\n",
    "                delta = vec * pct_move\n",
    "\n",
    "        #if verbose>0: print(f\"{vec=} {vecnorm=} {grad=} {lr*grad=} {delta=}\")\n",
    "        # perhaps modify the force from pure-parabolic to something\n",
    "        # with both long-range attraction and some mindist-repulsion.\n",
    "        #   (like Morse curve?)\n",
    "        # or just \"if vecnorm < mindist: NOOP\"\n",
    "        # (or some smooth-ish 90% that fades to zero as vecnorm < ~mindist?)\n",
    "\n",
    "        newpos = pts[idx,:] + delta\n",
    "        if verbose>0: print(f\"pt {idx} {pts[idx,:]} --> newpos {newpos}\")\n",
    "        \n",
    "        pts[idx,:] = newpos\n",
    "\n",
    "        #\n",
    "        # Is a quick approx update of cl_avg feasible?\n",
    "        cl_avg_new = cl_avg + delta/len(cluster_pts)\n",
    "        if verbose>0: print(f\"cluster {c} : {cl_avg_new=}\")\n",
    "        #\n",
    "        # NO! but YES if idx is only in a single cluster\n",
    "        #  Above simplicity does not work, because ALL cluster centers in which\n",
    "        #  pts[idx] participates must be updated,\n",
    "        #  (not just current cluster 'c')\n",
    "        # BUT OK for disjoint cluster memberships (pt never in 2 clusters)\n",
    "\n",
    "        return\n",
    "\n",
    "    assert( len(idx_cl) > 1 )\n",
    "    # Note: if point is in two clusters, pt moves first toward one,\n",
    "    #       then toward next, in SAME pattern.\n",
    "    # Better might be to 1st determine NET gradient direction from\n",
    "    # weighted sum of individual gradient forces,\n",
    "    # with movement \"capped\" at some weighted avg of cluster centers?\n",
    "    #\n",
    "    # Skip for now (assume multi-cluster membership is rare-ish)\n",
    "    #\n",
    "    cl_avgs = []\n",
    "    if verbose>0: print(\"\\npush pt\",idx,\"towards cluster centers\",idx_cl)\n",
    "    for c in idx_cl:\n",
    "        cluster_pts  = np_cluster_lists[c] # perhaps faster/vectorizable\n",
    "        if len(cluster_pts) <= 1:\n",
    "            cl_avgs.append(None)\n",
    "            print(\"noop: cluster empty or of size 1\")\n",
    "            continue\n",
    "        if verbose>2: print(f\"{cluster_pts=}\")\n",
    "\n",
    "        # cl_avg ~ cluster center\n",
    "        #cl_avg = np.zeros((pts.shape[1]), dtype=np.float32)\n",
    "        #for pt in cluster_pts:\n",
    "        #    #if verbose: print(\"sum += \",pts[pt])\n",
    "        #    cl_avg += pts[pt]\n",
    "        #if len(cluster_pts) > 1:\n",
    "        #    cl_avg /= len(cluster_pts)\n",
    "        cl_avg = np.mean(pts[cluster_pts,:], axis=0)\n",
    "        if verbose>1: print(f\"{cl_avg=}\")\n",
    "        cl_avgs.append(cl_avg)\n",
    "\n",
    "    tot_grad = np.zeros(pts.shape[1],dtype=np.float32)\n",
    "    eqm_pos  = np.zeros(pts.shape[1],dtype=np.float32)\n",
    "    sum_springs = np.sum(np_springs) #0.0\n",
    "    if verbose>1: print(f\"{sum_springs=}\")\n",
    "    #grad = None # we don't use this variable here\n",
    "    for (i,c) in enumerate(idx_cl):\n",
    "        # equilibrium target is spring-weighted center-of-mass\n",
    "        eqm_pos += np_springs[c] * cl_avgs[i]\n",
    "        # springs -> force gradient -> non-overshooting 'delta' movement\n",
    "        vec = cl_avgs[i] - pts[idx]      # vector toward cluster center\n",
    "        #vecnorm = np.linalg.norm(vec)\n",
    "        #grad = springs[c] * vecnorm     # gradient, in dirn vec/vecnorm\n",
    "        #tot_grad += (spring[c] * vecnorm) * (vec/vecnorm)\n",
    "        #  so we vecnorm cancels, leaving simply:\n",
    "        tot_grad += np_springs[c] * vec\n",
    "\n",
    "    eqm_pos /= sum_springs\n",
    "    if verbose>0: print(f\"{eqm_pos=}\")\n",
    "    if verbose>1: print(f\"{tot_grad=}\")\n",
    "\n",
    "    if True: # assert\n",
    "        # tot_grad should automatically be in direction of eqm_pos\n",
    "        # if math is correct:\n",
    "        grad_dirn = tot_grad / np.linalg.norm(tot_grad)\n",
    "        eqm_dirn  = eqm_pos - pts[idx]\n",
    "        eqm_dirn /= np.linalg.norm(eqm_dirn)\n",
    "        assert( np.allclose(grad_dirn, eqm_dirn) )\n",
    "\n",
    "    # at this point we have net gradient and terminal eqm_pos\n",
    "    # we proceed as before, so that the force is toward eqm_pos\n",
    "    # but the point never overshoots.\n",
    "    if True: # original.\n",
    "        #\n",
    "        #  Here we work directly with eqm_pos and totgrad\n",
    "        #  and ignore mindist.\n",
    "        #\n",
    "        vec = eqm_pos - pts[idx]      # vector toward spring-weighted equilibrium\n",
    "        vecnorm = np.linalg.norm(vec)\n",
    "        gradnorm = np.linalg.norm(tot_grad)\n",
    "        if verbose>2: print(f\"{gradnorm=}\")\n",
    "        #   v.0: by simply capping movement to \"100% of the way to cluster avg\"\n",
    "        #       N.B. for cluster avg 100%, without mindist\n",
    "        frac_mv = min(1.0, (lr * gradnorm) / vecnorm)\n",
    "        delta = vec * frac_mv\n",
    "        if verbose>1: print(f\"{vecnorm=} {gradnorm=}\")\n",
    "        elif verbose>2: print(f\"{vec=} {vecnorm=} {gradnorm=} {frac_mv=} {delta=}\")\n",
    "        #\n",
    "        # cf\n",
    "        # without minidst (i.e. bar = vecnorm)\n",
    "        #vec = eqm_pos - pts[idx]      # vector toward spring-weighted equilibrium\n",
    "        #vecnorm = np.linalg.norm(vec)\n",
    "        #if vecnorm > 1e-5:\n",
    "        #    #mv = lr * np.linalg.norm(tot_grad)  # lr : force --> distance\n",
    "        #    #mv = min(mv, vecnorm)\n",
    "        #    #pts[idx,:] += (mv/vecnorm) * vec\n",
    "        #    #...aka\n",
    "        #    #mv = lr * np.linalg.norm(tot_grad)  # lr : force --> distance\n",
    "        #    #mv = min(1.0, mv/vecnorm)\n",
    "        #    #pts[idx,:] += mv * vec\n",
    "        #    #...aka\n",
    "        #    pts[idx,:] += min(1.0, mv/vecnorm) * vec\n",
    "\n",
    "    #else: # use same function to calc delta\n",
    "    #    eqm_spring  (develop in next cell)\n",
    "    #    delta = spring_mv_v0(pts[idx], cl_avg, , lr, mindist)\n",
    "\n",
    "    # perhaps modify the force from pure-parabolic to something\n",
    "    # with both long-range attraction and some mindist-repulsion.\n",
    "    #   (like Morse curve?)\n",
    "    # or just \"if vecnorm < mindist: NOOP\"\n",
    "    # (or some smooth-ish 90% that fades to zero as vecnorm < ~mindist?)\n",
    "\n",
    "    newpos = pts[idx,:] + delta\n",
    "    if verbose>0: print(f\"pt {idx} {pts[idx,:]} --> newpos {newpos}\")\n",
    "    \n",
    "    pts[idx,:] = newpos\n",
    "    if verbose>0: print(f\"final {pts[idx,:]=}\")\n",
    "\n",
    "    #\n",
    "    # Is a quick approx update of cl_avg feasible?\n",
    "    #cl_avg_new = cl_avg + delta/len(cluster_pts)\n",
    "    #if verbose>0: print(f\"cluster {c} : {cl_avg_new=}\")\n",
    "    #\n",
    "    # NO!\n",
    "    #  Above simplicity does not work, because ALL cluster centers in which\n",
    "    #  pts[idx] participates must be updated,\n",
    "    #  (not just current cluster 'c')\n",
    "    # BUT OK for disjoint cluster memberships (pt never in 2 clusters)\n",
    "    return\n",
    "    \n",
    "def do_clustering_pts(pts, cluster_lists, springs, *, lr=1.0, mindist=0.01):\n",
    "    assert len(pts.shape) == 2\n",
    "    n_samples = pts.shape[0]\n",
    "    # one round of clustering every point once\n",
    "    for idx in range(n_samples):\n",
    "        pt0 = pts[idx,:].copy()\n",
    "        do_clustering_ipts(idx, pts, cluster_lists, springs, lr=lr, mindist=mindist)\n",
    "        print(f\"{idx=} {pt0=} --> {pts[idx,:]=}\")\n",
    "    return\n",
    "        \n",
    "do_clustering_pts(pts, cluster_lists, springs, lr=lr, mindist=0.2)\n",
    "print(\"final positions (one epoch)\")\n",
    "for i in range(pts.shape[0]):\n",
    "    print(f\"{i=} pt = {pts[i,:]}\")\n",
    "\n",
    "pts_ref = pts.copy()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's demo python clustering internals (no-debug version)\n",
      "type(pts)=<class 'numpy.ndarray'> pts.shape=(8, 2) pts.dtype=dtype('float32')\n",
      "eqm_pos=array([4.2038097, 1.       ], dtype=float32)\n",
      "final positions (one epoch)\n",
      "i=0 pt = [0. 0.]\n",
      "i=1 pt = [1.64 1.  ]\n",
      "i=2 pt = [4.2038097 1.       ]\n",
      "i=3 pt = [2.9708064  0.37381905]\n",
      "i=4 pt = [4. 1.]\n",
      "i=5 pt = [5. 2.]\n",
      "i=6 pt = [5.808576  0.4808495]\n",
      "i=7 pt = [5.8691216 0.8527701]\n",
      "Good: matched pts_ref\n",
      "Goodbye\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's demo python clustering internals (no-debug version)\")\n",
    "#\n",
    "# --------------------- Inputs -----------------\n",
    "#\n",
    "n_samples = 8\n",
    "cluster_lists = [[1,2,3], [2,7,6]]\n",
    "#           avg    2.0      5.0\n",
    "# each of the 2 clusters has a spring constant\n",
    "springs = np.array([0.8, 2.0])\n",
    "lr = 1.0   # learning rate (gradient multiplier) for spring forces\n",
    "\n",
    "pts = np.ndarray((n_samples,2), dtype=np.float32)\n",
    "for i in range(n_samples):\n",
    "    pts[i,:] = (float(i),float(i%3))\n",
    "\n",
    "n_samples = 8\n",
    "cluster_lists = [[1,2,3], [2,7,6]]\n",
    "#           avg    2.0      5.0\n",
    "# each of the 2 clusters has a spring constant\n",
    "springs = np.array([0.8, 2.0])\n",
    "lr = 1.0   # learning rate (gradient multiplier) for spring forces\n",
    "\n",
    "pts = np.ndarray((n_samples,2), dtype=np.float32)\n",
    "for i in range(n_samples):\n",
    "    pts[i,:] = (float(i),float(i%3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# ---------------------- Functions --------------\n",
    "#\n",
    "\n",
    "# begin with 2 very simple helpers\n",
    "@numba.njit()\n",
    "def np_mean_axis_0(pts):\n",
    "    cl_avg = np.zeros((pts.shape[1]), dtype=np.float32)\n",
    "    for pt in range(pts.shape[0]):\n",
    "        cl_avg += pts[pt,:]\n",
    "    assert pts.shape[0] > 0\n",
    "    cl_avg /= pts.shape[0]\n",
    "    return cl_avg\n",
    "\n",
    "@numba.njit() # eventually should just inline this wherever\n",
    "def xnp_cluster_list(c, clusters):\n",
    "    return np.argwhere(clusters[c,:]).flatten()\n",
    "\n",
    "\n",
    "\n",
    "#@numba.njit()\n",
    "def do_clustering_ipts(idx, pts, cluster_lists, springs, *, lr=1.0, mindist=0.01):\n",
    "    assert len(pts.shape) == 2\n",
    "    n_samples = pts.shape[0]\n",
    "    n_clust = len(cluster_lists)\n",
    "    assert n_clust > 0\n",
    "    assert len(springs) == len(cluster_lists)\n",
    "    np_cluster_lists = [np.array(clist,np.int32) for clist in cluster_lists]\n",
    "    np_springs = np.array(springs)\n",
    "    #\n",
    "    # cluster membership as bool array[cluster index][point index]\n",
    "    #\n",
    "    clusters = np.full((n_clust, n_samples), False, dtype=bool)\n",
    "    for (c,members) in enumerate(cluster_lists):\n",
    "        for m in members:\n",
    "            clusters[c][m] = True\n",
    "    \n",
    "    idx_in = clusters[:,idx]\n",
    "    idx_cl = np.argwhere(idx_in).flatten()\n",
    "    #\n",
    "    if len(idx_cl) < 1:\n",
    "        return\n",
    "\n",
    "    elif len(idx_cl) == 1:\n",
    "        # Separate out an easy case (idx in single cluster)\n",
    "        c = idx_cl[0]\n",
    "        cluster_pts  = np_cluster_lists[c] # perhaps faster/vectorizable\n",
    "        if len(cluster_pts) <= 1:\n",
    "            print(\"noop: cluster empty or of size 1\")\n",
    "            return\n",
    "\n",
    "        # cl_avg ~ cluster center\n",
    "        cl_avg = np.mean(pts[cluster_pts,:], axis=0)\n",
    "        cl_avg2 = np_mean_axis_0( pts[cluster_pts,:] )  # cluster centroid\n",
    "        #print(f\"{idx=} {cl_avg=}\\n{cl_avg2=}\")\n",
    "\n",
    "        delta = spring_mv_v0(pts[idx], cl_avg, springs[c], lr, mindist)\n",
    "        pts[idx,:] += delta\n",
    "\n",
    "        # A quick approx update of cl_avg feasible, but don't use it for now\n",
    "        #cl_avg_new = cl_avg + delta/len(cluster_pts)\n",
    "        # It's trickier for len(idx_cl) > 1 (more updates needed!)\n",
    "\n",
    "        return\n",
    "\n",
    "    assert( len(idx_cl) > 1 )\n",
    "    # Easy: if point is in two clusters, pt moves first toward one,\n",
    "    #       then toward next, in SAME pattern.\n",
    "    #\n",
    "    # Actual: 1st determine NET gradient direction from\n",
    "    #         weighted sum of individual gradient forces,\n",
    "    #         with movement not to overshoot weighted \"equilibrium\"\n",
    "    #         position derived from weighted avg of cluster centers\n",
    "    #\n",
    "    tot_grad = np.zeros(pts.shape[1],dtype=np.float32)\n",
    "    eqm_pos  = np.zeros(pts.shape[1],dtype=np.float32)\n",
    "    sum_springs = 0.0 #np.sum(np_springs)\n",
    "    n_springs = 0\n",
    "    if False: # first way, 2 loops\n",
    "        cl_avgs = []\n",
    "        for c in idx_cl:\n",
    "            cluster_pts  = np_cluster_lists[c] # perhaps faster/vectorizable\n",
    "            if len(cluster_pts) < 1:\n",
    "                cl_avgs.append(None)\n",
    "                print(\"noop: cluster empty or of size 1\")\n",
    "                continue\n",
    "            # cl_avg ~ cluster center\n",
    "            cl_avg = np.mean(pts[cluster_pts,:], axis=0)\n",
    "            cl_avgs.append(cl_avg)\n",
    "            n_springs += 1\n",
    "\n",
    "        tot_grad = np.zeros(pts.shape[1],dtype=np.float32)\n",
    "        eqm_pos  = np.zeros(pts.shape[1],dtype=np.float32)\n",
    "        sum_springs = np.sum(np_springs) # correct if all clusters non-empty\n",
    "\n",
    "        # calculate equilibrium spring-weight target position\n",
    "        #           and total spring-weighted gradient\n",
    "        # every cluster exerts a force ind't of cluster size\n",
    "        for (i,c) in enumerate(idx_cl):\n",
    "            if cl_avgs[i] is not None: # i.e. the cluster is non-empty, has a centroid\n",
    "                # springs -> force gradient -> non-overshooting 'delta' movement\n",
    "                eqm_pos += np_springs[c] * cl_avgs[i]\n",
    "                vec = cl_avgs[i] - pts[idx,:]      # vector toward cluster center\n",
    "                tot_grad += np_springs[c] * vec\n",
    "\n",
    "        eqm_pos /= sum_springs\n",
    "    \n",
    "    else: # shorter way: combine loops\n",
    "\n",
    "        # calculate equilibrium spring-weight target position\n",
    "        #           and total spring-weighted gradient\n",
    "        # every cluster exerts a force ind't of cluster size\n",
    "        for c in idx_cl:\n",
    "            cluster_pts  = xnp_cluster_list(c, clusters) # perhaps faster/vectorizable\n",
    "            # Note: 1. Each cluster centroid gets its spring regardless\n",
    "            #          of how populated the cluster is.\n",
    "            #       2. Size 1 cluster get included\n",
    "            #       3. Spring constant doubles as weighting factor -- this\n",
    "            #          might not hold for other spring force models!\n",
    "            if len(cluster_pts) > 0:\n",
    "                cl_avg = np_mean_axis_0( pts[cluster_pts,:] )\n",
    "                #print(f\"{c=} {cl_avg=}\")\n",
    "                # Now update sums for equilibrium posn and total gradient\n",
    "                # springs -> summed force gradient vectors\n",
    "                spring = np_springs[c]\n",
    "                sum_springs += spring\n",
    "                n_springs += 1\n",
    "                eqm_pos += spring * cl_avg\n",
    "                vec = cl_avg - pts[idx,:]      # vector toward cluster center\n",
    "                tot_grad += spring * vec       # only for kr^2 spring physics\n",
    "\n",
    "        eqm_pos /= sum_springs\n",
    "\n",
    "    print(f\"{eqm_pos=}\")\n",
    "\n",
    "    if True: # assert\n",
    "        # tot_grad should automatically be in direction of eqm_pos\n",
    "        # if math is correct:\n",
    "        grad_dirn = tot_grad / np.linalg.norm(tot_grad)\n",
    "        eqm_dirn  = eqm_pos - pts[idx,:]\n",
    "        eqm_dirn /= np.linalg.norm(eqm_dirn)\n",
    "        assert( np.allclose(grad_dirn, eqm_dirn) )\n",
    "\n",
    "    # I don't think mindist should apply to \"virtual\" avg-of-cluster-centroids\n",
    "    use_mindist_for_eqm = False\n",
    "    \n",
    "    if False and not use_mindist_for_eqm: # orig (no mindist)\n",
    "        #vec = eqm_pos - pts[idx]      # vector toward spring-weighted equilibrium\n",
    "        #vecnorm = np.linalg.norm(vec)\n",
    "        eqm_spring = np.linalg.norm(tot_grad) / np.linalg.norm(eqm_pos-pts[idx])\n",
    "        vec = eqm_pos - pts[idx]      # vector toward spring-weighted equilibrium\n",
    "        vecnorm = np.linalg.norm(vec)\n",
    "        print(f\"{eqm_spring=} {eqm_spring*vecnorm=}\")\n",
    "\n",
    "        # at this point we have net gradient and terminal eqm_pos\n",
    "        # we proceed as before, so that the force is toward eqm_pos\n",
    "        # but the point never overshoots.\n",
    "        #\n",
    "        # Can we use an \"effective spring constant\" for eqm_pos?\n",
    "        # or do we need a 'gradnorm'-based updater?\n",
    "        #\n",
    "        vec = eqm_pos - pts[idx]      # vector toward spring-weighted equilibrium\n",
    "        vecnorm = np.linalg.norm(vec)\n",
    "        gradnorm = np.linalg.norm(tot_grad)\n",
    "        # spring-physics model:\n",
    "        #    gradnorm = spring_effx * (displacement=vecnorm)\n",
    "        spring_effx = gradnorm / vecnorm\n",
    "        print(f\"{vecnorm=} {gradnorm=} {spring_effx=}\")\n",
    "        #   v.0: by simply capping movement to \"100% of the way to cluster avg\"\n",
    "        #        for movement to eqm posn, can move all the way?\n",
    "        pct_move = min(1.0, (lr * gradnorm)/vecnorm)\n",
    "        #   v.1: even for a move to eqm_pos, use a mindist2 guaranteed \"small\"\n",
    "        #mindist2 = min( mindist, 0.1 )\n",
    "        #pct_move = smoothstep( lr * gradnorm, vecnorm - 0.5*mindist2, vecnorm - mindist2 )\n",
    "        # above is WRONG\n",
    "        delta = vec * pct_move\n",
    "        \n",
    "        #def spring_mv_v0_plain(pt, target, spring, lr=1.0, mindist=0.0):\n",
    "        #   vec = target - pt      # vector toward cluster center\n",
    "        #    if mindist > 0.0:\n",
    "        #        vecnorm = np.linalg.norm(vec)\n",
    "        #        bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "        #        delta = (min(lr * spring, 1.0) * bar / vecnorm) * vec\n",
    "        #    else: # mindist == 0.0\n",
    "        #        delta = min(1.0, lr*spring) * vec\n",
    "        #    return delta\n",
    "        # with above cancellation, for mindist==0.0, we have just:\n",
    "        \n",
    "    elif True and not use_mindist_for_eqm: # orig (no mindist) -- extremely simple!\n",
    "        # almost too simple to be true\n",
    "        vec = eqm_pos - pts[idx]      # vector toward spring-weighted equilibrium\n",
    "        gradnorm = np.linalg.norm(tot_grad)\n",
    "        delta = min(1.0, lr * gradnorm) * vec\n",
    "        #                     ^^^^^^^^ replaces 'spring'\n",
    "        \n",
    "    else: # with min_dist : now the \"target\" is not eqm_pos, but a point mindist away from it\n",
    "        # In principle:\n",
    "        #eqm_spring = np.linalg.norm(tot_grad) / max(1.e-6, (np.linalg.norm(eqm_pos-pts[idx]) - mindist))\n",
    "        # But for targets that are \"midway\" between several clusters, maybe it is best to NOT\n",
    "        # use mindist\n",
    "        #delta = spring_mv_v0(pts[idx], eqm_pos, eqm_spring, lr, mindist)\n",
    "        #\n",
    "        # or long-hand:\n",
    "        vec = eqm_pos - pts[idx]            # vector toward spring-weighted equilibrium\n",
    "        vecnorm = np.linalg.norm(vec)\n",
    "        bar = max(vecnorm - mindist, 0.0)   # max move dist (along vec/vecnorm)\n",
    "        gradnorm = np.linalg.norm(tot_grad) # this replaces 'spring' in spring_mv_v0_plain\n",
    "        delta = (min(lr * gradnorm, 1.0) * bar / vecnorm) * vec\n",
    "\n",
    "\n",
    "    if True:\n",
    "        pts[idx,:] = pts[idx,:] + delta\n",
    "    else: # verbose\n",
    "        newpos = pts[idx,:] + delta\n",
    "        print(f\"pt {idx} {int(pct_move*100.)}% {pts[idx,:]} --> newpos {newpos}\")\n",
    "        pts[idx,:] = newpos\n",
    "        print(f\"final {pts[idx,:]=}\")\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "#@numba.njit()\n",
    "def do_clustering_pts(pts, cluster_lists, springs, *, lr=1.0, mindist=0.01):\n",
    "    assert len(pts.shape) == 2\n",
    "    n_samples = pts.shape[0]\n",
    "    # one round of clustering every point once\n",
    "    for idx in range(n_samples):\n",
    "        #pt0 = pts[idx,:].copy()\n",
    "        do_clustering_ipts(idx, pts, cluster_lists, springs, lr=lr, mindist=mindist)\n",
    "        #print(f\"{idx=} {pt0=} --> {pts[idx,:]=}\")\n",
    "    return\n",
    "\n",
    "print(f\"{type(pts)=} {pts.shape=} {pts.dtype=}\")\n",
    "do_clustering_pts(pts, cluster_lists, springs, lr=lr, mindist=0.2)\n",
    "print(\"final positions (one epoch)\")\n",
    "for i in range(pts.shape[0]):\n",
    "    print(f\"{i=} pt = {pts[i,:]}\")\n",
    "\n",
    "if pts_ref is not None:\n",
    "    assert( np.allclose(pts, pts_ref) )\n",
    "    print(\"Good: matched pts_ref\")\n",
    "else:\n",
    "    pts_ref = pts.copy()\n",
    "print(\"Goodbye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's demo python clustering internals (jit version)\n",
      "This cell is the precursor a new file umap/constrain_clust.py\n",
      "\n",
      "idx=1 c=0 centroid=array([2., 1.], dtype=float32)\n",
      "pt0=array([1., 1.], dtype=float32) --> [1.64 1.  ]\n",
      "idx=3 c=0 centroid=array([2.9479363, 0.6666667], dtype=float32)\n",
      "pt0=array([3., 0.], dtype=float32) --> [2.9708064  0.37381905]\n",
      "idx=6 c=1 centroid=array([5.7346034, 0.6666667], dtype=float32)\n",
      "pt0=array([6., 0.], dtype=float32) --> [5.808576   0.48084953]\n",
      "idx=7 c=1 centroid=array([5.6707954 , 0.82694983], dtype=float32)\n",
      "pt0=array([7., 1.], dtype=float32) --> [5.8691216 0.8527701]\n",
      "final positions (one epoch)\n",
      "i=0 pt = [0. 0.]\n",
      "i=1 pt = [1.64 1.  ]\n",
      "i=2 pt = [4.2038097 1.       ]\n",
      "i=3 pt = [2.9708064  0.37381905]\n",
      "i=4 pt = [4. 1.]\n",
      "i=5 pt = [5. 2.]\n",
      "i=6 pt = [5.808576   0.48084953]\n",
      "i=7 pt = [5.8691216 0.8527701]\n",
      "Good: matched pts_ref\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "print(\"Let's demo python clustering internals (jit version)\")\n",
    "print(\"This cell is the precursor a new file umap/constrain_clust.py\\n\")\n",
    "\n",
    "#\n",
    "# ---------------------- Functions --------------\n",
    "# ouch.  these must be jittable now\n",
    "# numba cannot handle a python list of numpy arrays.\n",
    "# Let's break things apart to find numba-ready code blocks\n",
    "#\n",
    "@numba.njit()\n",
    "def np_mean_axis_0(pts):\n",
    "    cl_avg = np.zeros((pts.shape[1]), dtype=np.float32)\n",
    "    for pt in range(pts.shape[0]):\n",
    "        cl_avg += pts[pt,:]\n",
    "    assert pts.shape[0] > 0\n",
    "    cl_avg /= pts.shape[0]\n",
    "    return cl_avg\n",
    "\n",
    "@numba.njit() # approx. void(i8, f4[:,:], i8[:], f8, f8)\n",
    "#def xdo_clustering_single(idx, pts, cluster_pts, lr, spring):\n",
    "def xdo_clustering_ipts_toward0(idx, pts, target, lr, spring, maxfrac=0.9):\n",
    "    \"\"\" Non-overshooting move of pts[idx,:] towards cofm(pts[cluster_pts]).\n",
    "    \n",
    "        In this version, maxfrac=0.9 is an under-relaxation \"don't go all the way\".\n",
    "    \"\"\"\n",
    "    if lr*spring > 1e-5:\n",
    "        vec = target - pts[idx,:]\n",
    "        vecsz = np.linalg.norm(vec)         # stepsz is distance ~ spring force * lr\n",
    "        stepsz = lr * (spring * vecsz)\n",
    "        fracsz = min(maxfrac, stepsz/vecsz) # maxfrac<1 => undershoot\n",
    "        pts[idx,:] += fracsz * vec\n",
    "    # v.1  attempt to smooth the transition\n",
    "    #vec = cl_avg - pts[idx]      # vector toward cluster center\n",
    "    #vecnorm = np.linalg.norm(vec)\n",
    "    #if vecnorm <= mindist: # no-op - pt is already within mindist of cl_avg\n",
    "    #    delta = vec * 0.0\n",
    "    #else:\n",
    "    #    grad = np_springs[c] * vecnorm\n",
    "    #    gradnorm = lr * grad\n",
    "    #    edge0 = max(vecnorm - 2*mindist, 0.0)\n",
    "    #    edge1 = vecnorm - mindist\n",
    "    #    if gradnorm <= edge0:\n",
    "    #        delta = vec\n",
    "    #    else:\n",
    "    #        mvlen = edge0 + (edge1-edge0) * smoothstep( gradnorm, edge0, edge1 )\n",
    "    #        delta = vec * (mvlen/vecnorm)\n",
    "    #delta = vec * pct_move\n",
    "    return\n",
    "    #\n",
    "    # compare with multi-cluster case, where we calc tot_grad up front\n",
    "    # as a spring-weighted sum of force vectors\n",
    "    #\n",
    "    #if True:\n",
    "    #    # at this point we have net gradient and terminal eqm_pos\n",
    "    #    # we proceed as before, so that the force is toward eqm_pos\n",
    "    #    # but the point never overshoots.\n",
    "    #    #   v.0: by simply capping movement to \"100% of the way to cluster avg\"\n",
    "    #    #        for movement to eqm posn, can move all the way?\n",
    "    #    eqm_pos = target\n",
    "    #    vec = eqm_pos - pts[idx]\n",
    "    #    vecnorm = np.linalg.norm(vec)\n",
    "    #    gradnorm = np.linalg.norm(tot_grad) # gradnorm is NOT spring * vecnorm\n",
    "    #    pct_move = min(1.0, (lr * gradnorm) / vecnorm)\n",
    "    #    delta = vec * pct_move\n",
    "    #\n",
    "    # this can be reproduced by an \"effective spring const\"\n",
    "    #   gradnorm = np.linalg.norm(tot_grad)\n",
    "    # == ?\n",
    "    #   spring_eff * np.linalg.norm(target-pts[idx])\n",
    "    # IFF\n",
    "    #   spring_eff = np.linalg.norm(target-pts[idx]) / np.linalg.norm(tot_grad)\n",
    "    #\n",
    "\n",
    "#if False: # for reference\n",
    "#    def spring_mv_v0_plain(pt, target, spring, lr=1.0, mindist=0.0):\n",
    "#        vec = target - pt      # vector toward cluster center\n",
    "#        vecnorm = np.linalg.norm(vec)\n",
    "#        if mindist > 0.0:\n",
    "#            bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "#            delta = (min(lr * spring, 1.0) * bar / vecnorm) * vec\n",
    "#        else: # mindist == 0.0\n",
    "#            delta = min(1.0, lr*spring) * vec\n",
    "#        return delta\n",
    "\n",
    "@numba.njit() # approx. void(i8, f4[:,:], i8[:], f8, f8)\n",
    "def xdo_clustering_ipts_toward(idx, pts, target, lr, spring, mindist=0.0):\n",
    "    \"\"\" Non-overshooting move of pts[idx,:] towards cofm(pts[cluster_pts]).\n",
    "    \n",
    "        lr: time step (1.0 will move exactly to equilibrium posn if spring==1)\n",
    "        \n",
    "        spring : spring constant \"force ~ spring * displacement\" (parabolic potential)\n",
    "        \n",
    "        mindist: to \"not go all the way\" towards target, but stop mindist away.\n",
    "    \"\"\"\n",
    "    # Using maxfrac:\n",
    "    #if lr*spring > 1e-5:\n",
    "    #    vec = target - pts[idx,:]\n",
    "    #    vecsz = np.linalg.norm(vec)         # stepsz is distance ~ spring force * lr\n",
    "    #    stepsz = lr * (spring * vecsz)\n",
    "    #    fracsz = min(maxfrac, stepsz/vecsz) # maxfrac<1 => undershoot\n",
    "    #    pts[idx,:] += fracsz * vec\n",
    "    #return\n",
    "    \n",
    "    # mindist python move fn:\n",
    "    #def spring_mv_v0_plain(pt, target, spring, lr=1.0, mindist=0.0):\n",
    "    #   vec = target - pt      # vector toward cluster center\n",
    "    #    if mindist > 0.0:\n",
    "    #        vecnorm = np.linalg.norm(vec)\n",
    "    #        bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "    #        delta = (min(lr * spring, 1.0) * bar / vecnorm) * vec\n",
    "    #  or just delta = (min(bar, bar * lr * spring) / vecnorm) * vec\n",
    "    #    else: # mindist == 0.0\n",
    "    #        delta = min(1.0, lr*spring) * vec\n",
    "    #    return delta\n",
    "    \n",
    "    # movement with mindist (patterned after python helper \"spring_mv_v0\")\n",
    "    vec = target - pts[idx,:]      # vector toward cluster center\n",
    "    vecnorm = np.linalg.norm(vec)\n",
    "    if vecnorm > 1e-5:\n",
    "        bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "        #delta = (min(lr * spring, 1.0) * bar / vecnorm) * vec\n",
    "        mv = min(bar, bar * lr * spring)\n",
    "        pts[idx,:] += (mv/vecnorm) * vec\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "@numba.njit() # eventually should just inline this wherever\n",
    "def xnp_cluster_list(c, clusters):\n",
    "    return np.argwhere(clusters[c,:]).flatten()\n",
    "\n",
    "@numba.njit(\n",
    "    locals={'tot_grad': numba.float32[:],\n",
    "            'eqm_pos' : numba.float32[:],\n",
    "            'sum_springs' : numba.float32,\n",
    "            'n_springs'   : numba.int64,\n",
    "           }\n",
    ")\n",
    "def xdo_clustering_mult(idx, idx_cl, clusters, springs, pts):\n",
    "    \"\"\" return target+grad info for idx w/ springs to  multiple clusters. \"\"\"\n",
    "    tot_grad = np.zeros(pts.shape[1],dtype=np.float32)\n",
    "    eqm_pos  = np.zeros(pts.shape[1],dtype=np.float32)\n",
    "    sum_springs = 0.0 #np.sum(np_springs)\n",
    "    n_springs = 0\n",
    "\n",
    "    # calculate equilibrium spring-weight target position\n",
    "    #           and total spring-weighted gradient\n",
    "    # every cluster exerts a force ind't of cluster size\n",
    "    for cc in idx_cl:\n",
    "        cluster_pts  = xnp_cluster_list(cc, clusters) # perhaps faster/vectorizable\n",
    "        # Note: 1. Each cluster centroid gets its spring regardless\n",
    "        #          of how populated the cluster is.\n",
    "        #       2. Size 1 cluster get included\n",
    "        #       3. Spring constant doubles as weighting factor -- this\n",
    "        #          might not hold for other spring force models!\n",
    "        if len(cluster_pts) > 0:\n",
    "            cl_avg = np_mean_axis_0( pts[cluster_pts,:] )\n",
    "            #print(f\"{cc=} {cluster_pts=}{cl_avg=}\")\n",
    "            # Now update sums for equilibrium posn and total gradient\n",
    "            # springs -> force gradient -> non-overshooting 'delta' movement\n",
    "            spring = springs[cc]\n",
    "            sum_springs += spring\n",
    "            n_springs += 1\n",
    "            eqm_pos += spring * cl_avg\n",
    "            vec = cl_avg - pts[idx,:]      # vector toward cluster center\n",
    "            tot_grad += spring * vec       # only for kr^2 spring physics\n",
    "    #\n",
    "    eqm_pos /= sum_springs\n",
    "\n",
    "    return (n_springs, eqm_pos, tot_grad)\n",
    "\n",
    "#@numba.njit(\"void(i8, f4[:,:], boolean[:,:], f4[:], f8, f8)\")\n",
    "def xdo_clustering_ipts(idx, pts, clusters, springs, lr=1.0, mindist=0.01):\n",
    "    #assert len(pts.shape) == 2\n",
    "    n_samples = pts.shape[0]\n",
    "    n_clust = springs.shape[0] # it is a vector, one per cluster\n",
    "    #  otherwise n_clust = np.max(clusters) + 1\n",
    "    #n_clust = len(np_cluster_lists)\n",
    "    #assert n_clust > 0\n",
    "    #assert len(springs) == len(np_cluster_lists)\n",
    "    #np_cluster_lists = [np.array(clist,np.int32) for clist in cluster_lists]\n",
    "    #np_springs = np.array(springs)\n",
    "    idx_in = clusters[:,idx]\n",
    "    idx_cl = np.argwhere(idx_in).flatten()\n",
    "\n",
    "    if len(idx_cl) < 1:\n",
    "        return\n",
    "\n",
    "    elif len(idx_cl) == 1:\n",
    "        # Separate out an easy case (idx in single cluster)\n",
    "        c = idx_cl[0]\n",
    "        cluster_pts  = xnp_cluster_list(c, clusters)\n",
    "        # pts[idx] in a cluster of size 1 is already at the cluster centroid\n",
    "        if len(cluster_pts) > 1:\n",
    "            centroid = np_mean_axis_0( pts[cluster_pts,:] )  # cluster centroid\n",
    "            pt0 = pts[idx,:].copy()\n",
    "            xdo_clustering_ipts_toward(idx, pts, centroid,\n",
    "                                       lr, springs[c], mindist=mindist)\n",
    "            print(f\"{idx=} {c=} {centroid=}\\n{pt0=} --> {pts[idx]}\")\n",
    "        return\n",
    "\n",
    "    #else: idx attracted to multiple clusters... len(idx_cl) > 1 ... rare?\n",
    "    # jit test:\n",
    "    (n_springs, eqm_pos, tot_grad) = xdo_clustering_mult(idx, idx_cl, clusters, springs, pts)\n",
    "    \n",
    "    if n_springs==0:  # all clusters empty? No-op\n",
    "        return\n",
    "\n",
    "    if True:\n",
    "        # multi-cluster effective spring constant, to re-use \"_toward\" code...\n",
    "        #  This way re-uses existing code but redoes some vector calcs\n",
    "        eqm_spring = np.linalg.norm(tot_grad) / np.linalg.norm(eqm_pos-pts[idx])\n",
    "        #xdo_clustering_ipts_toward0(idx, pts, eqm_pos, lr, eqm_spring, maxfrac=1.0)\n",
    "        xdo_clustering_ipts_toward(idx, pts, eqm_pos, lr, eqm_spring, mindist=0.0)\n",
    "    elif False:\n",
    "        # Actually, with mindist 0 the calc is very simple, so longhand:\n",
    "        \n",
    "        # The calculation with mindist:\n",
    "        #vec = target - pt      # vector toward cluster center\n",
    "        #vecnorm = np.linalg.norm(vec)\n",
    "        #if vecnorm > 1e-5:\n",
    "        #    bar = max(vecnorm - mindist, 0.0) # max move dist (along vec/vecnorm)\n",
    "        #    mv = min(bar, lr * bar * spring)\n",
    "        #    pts[idx,:] += (mv/vecnorm) * vec\n",
    "        #return\n",
    "        \n",
    "        # without minidst (i.e. bar = vecnorm)\n",
    "        vec = eqm_pos - pts[idx]      # vector toward spring-weighted equilibrium\n",
    "        vecnorm = np.linalg.norm(vec)\n",
    "        if vecnorm > 1e-5:\n",
    "            mv = lr * np.linalg.norm(tot_grad)  # lr : force --> distance\n",
    "            mv = min(mv, vecnorm)\n",
    "            pts[idx,:] += (mv/vecnorm) * vec\n",
    "            #\n",
    "            #pts[idx,:] += ((min(vecnorm, lr*np.linalg.norm(tot_grad)) / vecnorm) * vec\n",
    "            #\n",
    "            #pts[idx,:] += (min(1.0, lr*np.linalg.norm(tot_grad))) * vec\n",
    "    else: # \"longhand\" (so simple for mindist=0.0)\n",
    "        vec = eqm_pos - pts[idx]      # vector toward spring-weighted equilibrium\n",
    "        mv = lr * np.linalg.norm(tot_grad)\n",
    "        #pts[idx,:] += min(1.0, mv) * vec\n",
    "        if mv < 1.0:\n",
    "            pts[idx,:] += mv * vec\n",
    "        else:\n",
    "            pts[idx,:] = eqm_pos\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#@numba.njit()\n",
    "def xdo_clustering_pts(pts, cluster2d, springs, lr=1.0, mindist=0.01):\n",
    "    assert len(pts.shape) == 2\n",
    "    n_samples = pts.shape[0]\n",
    "    # one round of clustering every point once\n",
    "    for idx in range(n_samples):\n",
    "        xdo_clustering_ipts(idx, pts, cluster2d, springs, lr, mindist)\n",
    "    return\n",
    "\n",
    "#\n",
    "# -------------- python (non-numba) --------------\n",
    "# These show how to convert python args to expected numba-compliant types\n",
    "#\n",
    "\n",
    "# for completeness, since this might also become a 'mk_FOO' jit-fn-generator\n",
    "def do_clustering_ipts_py(idx, pts, cluster_lists, springs, lr, mindist):\n",
    "    \"\"\" python-ish front-end, with appropriate setup for just internals.\n",
    "\n",
    "        pts: array[n_samples,dim]  sample ~ \"idx\"\n",
    "        clusters: list-of-lists ~ (cluster, idx)\n",
    "        springs: python list of numbers (np array[:]\n",
    "        lr, mindist: python numbers\n",
    "    \"\"\"\n",
    "    idx = int(idx)\n",
    "    lr = float(lr)\n",
    "    mindist = float(mindist)\n",
    "    assert len(pts.shape) == 2\n",
    "    assert len(cluster_lists) == len(springs)\n",
    "    n_samples = pts.shape[0]\n",
    "    assert idx < pts.shape[0]\n",
    "    \n",
    "    #np_cluster_lists = [np.array(clist,np.int32) for clist in cluster_lists]\n",
    "    n_clust = len(cluster_lists)\n",
    "\n",
    "    if n_samples==0 or n_clust==0:\n",
    "        return\n",
    "    \n",
    "    #\n",
    "    # generalization:  clusters[c,idx] is True IFF idx is in cluster c\n",
    "    clusters = np.full((n_clust, n_samples), False, dtype=bool)\n",
    "    for (c,members) in enumerate(cluster_lists):\n",
    "        for m in members:\n",
    "            clusters[c][m] = True\n",
    "            \n",
    "    springs = np.array(springs, dtype=np.float32)  # don't need python float64 default\n",
    "    # no negative or inf or nan springs\n",
    "    assert np.all(springs >= 0.0)  # actually nan is also NOT >= 0 so elision...\n",
    "    assert np.count_nonzero((springs == np.inf) | (springs == np.nan)) == 0\n",
    "    \n",
    "    # pts is to be modified -- do not create a copy!\n",
    "    \n",
    "    # invoke jit fn (or create and return it)\n",
    "    xdo_clustering_pts( pts, clusters, springs, lr=lr, mindist=mindist )\n",
    "\n",
    "    return\n",
    "\n",
    "# python \"frontend-to-jit\" demo for cell output\n",
    "def do_clustering_pts_py(pts, cluster_lists, springs, lr, mindist):\n",
    "    \"\"\" python-ish front-end, with appropriate setup for just internals.\n",
    "\n",
    "        pts: array[n_samples,dim]  sample ~ \"idx\"\n",
    "        clusters: list-of-lists ~ (cluster, idx)\n",
    "        springs: python list of numbers\n",
    "        lr, mindist: python numbers\n",
    "    \"\"\"\n",
    "    lr = float(lr)\n",
    "    mindist = float(mindist)\n",
    "    assert len(pts.shape) == 2\n",
    "    assert len(cluster_lists) == len(springs)\n",
    "    n_samples = pts.shape[0]\n",
    "    \n",
    "    #np_cluster_lists = [np.array(clist,np.int32) for clist in cluster_lists]\n",
    "    n_clust = len(cluster_lists)\n",
    "    \n",
    "    if n_samples==0 or n_clust==0:\n",
    "        return\n",
    "    \n",
    "    clusters = np.full((n_clust, n_samples), False, dtype=bool)\n",
    "    for (c,members) in enumerate(cluster_lists):\n",
    "        for m in members:\n",
    "            clusters[c][m] = True\n",
    "            \n",
    "    springs = np.array(springs, dtype=np.float32)  # don't need python float64 default\n",
    "    # no negative or inf or nan springs\n",
    "    assert np.all(springs >= 0.0)  # actually nan is also NOT >= 0 so elision...\n",
    "    assert np.count_nonzero((springs == np.inf) | (springs == np.nan)) == 0\n",
    "    \n",
    "    # pts is to be modified -- do not create a copy!\n",
    "    \n",
    "    if False:\n",
    "        print(f\"{numba.typeof(pts)=} {pts.shape=}\")\n",
    "        print(f\"{numba.typeof(clusters)=}\")\n",
    "        print(f\"{numba.typeof(springs)=}\")\n",
    "        print(f\"{numba.typeof(lr)=}\")\n",
    "        print(f\"{numba.typeof(mindist)=}\")\n",
    "    \n",
    "    # invoke jit fn (or create and return it)\n",
    "    xdo_clustering_pts( pts, clusters, springs, lr=lr, mindist=mindist )\n",
    "    \n",
    "    return\n",
    "\n",
    "#\n",
    "# --------------------- Inputs -----------------\n",
    "#\n",
    "\n",
    "n_samples = 8\n",
    "cluster_lists = [[1,2,3], [2,7,6]]\n",
    "#           avg    2.0      5.0\n",
    "# each of the 2 clusters has a spring constant\n",
    "springs = np.array([0.8, 2.0], dtype=np.float32)\n",
    "lr = 1.0   # learning rate (gradient multiplier) for spring forces\n",
    "\n",
    "pts = np.ndarray((n_samples,2), dtype=np.float32)\n",
    "for i in range(n_samples):\n",
    "    pts[i,:] = (float(i),float(i%3))\n",
    "\n",
    "\n",
    "#np_cluster_lists = [np.array(clist,np.int32) for clist in cluster_lists]\n",
    "#n_clust = len(np_cluster_lists)\n",
    "## numba-friendly: single full-sized array\n",
    "##  TODO: compressed data,indptr,indices versions cluster and its transpose\n",
    "#\n",
    "## clusters[ c, idx ], for c in [0,n_clust] and idx in [0,n_samples),\n",
    "##         is True IFF idx is in cluster c\n",
    "#clusters = np.full((n_clust, n_samples), False, dtype=bool)\n",
    "#for (c,members) in enumerate(np_cluster_lists):\n",
    "#    for m in members:\n",
    "#        clusters[c][m] = True\n",
    "#print(f\"{numba.typeof(clusters)=}\")\n",
    "\n",
    "#\n",
    "# ------------------------ python/jit test -------------\n",
    "#\n",
    "mindist=0.2 # support TBD (need to rething equations)\n",
    "\n",
    "#xdo_clustering_pts(pts, clusters, springs, lr=lr, mindist=0.2)\n",
    "do_clustering_pts_py(pts, cluster_lists, springs, lr=lr, mindist=0.2)\n",
    "\n",
    "print(\"final positions (one epoch)\")\n",
    "for i in range(pts.shape[0]):\n",
    "    print(f\"{i=} pt = {pts[i,:]}\")\n",
    "\n",
    "try:\n",
    "    pts_ref\n",
    "    assert np.allclose(pts, pts_ref)\n",
    "    print(\"Good: matched pts_ref\")\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(\"Goodbye!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINALLY have some *mk_FOO*\n",
    "### jitted cluster-funcs\n",
    "\n",
    "#### What's the point?\n",
    "*umap-constraints, short-n-sweet* jitted \"lambda functions\" can be used\n",
    "as `data_constrain=` or `output_constrain=` args to umap euclidean\n",
    "embedding calls (`fit`, `fit_transform`)\n",
    "\n",
    "The umap embedding should *pull together* our **user-specified clusters**,\n",
    "with whatever effects these have on next-nearest members, etc. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final positions (one epoch)\n",
      "i=0 pt = [0. 0.]\n",
      "i=1 pt = [1.64 1.  ]\n",
      "i=2 pt = [4.2038097 1.       ]\n",
      "i=3 pt = [2.9708064  0.37381905]\n",
      "i=4 pt = [4. 1.]\n",
      "i=5 pt = [5. 2.]\n",
      "i=6 pt = [5.808576   0.48084953]\n",
      "i=7 pt = [5.8691216 0.8527701]\n",
      "Good: matched pts_ref\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Now try above cell as part of umap-constraints...\n",
    "# This call can run standalone:\n",
    "#   It invokes a jit-function mk_FOO,\n",
    "#   and then invokes it\n",
    "#   (umap.UMAP not involved)\n",
    "#\n",
    "#   I found the mk_FOO marks some local array refs 'readonly array'.\n",
    "#   It was easiest to simply remove the overly constraining specs\n",
    "#   and let @numba.njit() autogenerate the required signatures\n",
    "#   in umap/constrain_clust.py\n",
    "#\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "from umap.constrain_clust import mk_clustering_pts, mk_clustering_ipts\n",
    "\n",
    "#\n",
    "# ------- Inputs (python) -----------------------------\n",
    "n_samples = 8\n",
    "cluster_lists = [[1,2,3], [2,7,6]]\n",
    "#           avg    2.0      5.0\n",
    "# each of the 2 clusters has a spring constant\n",
    "springs = np.array([0.8, 2.0], dtype=np.float32)\n",
    "lr = 1.0   # learning rate (gradient multiplier) for spring forces\n",
    "\n",
    "pts = np.ndarray((n_samples,2), dtype=np.float32)\n",
    "for i in range(n_samples):\n",
    "    pts[i,:] = (float(i),float(i%3))\n",
    "\n",
    "mindist = 0.2\n",
    "\n",
    "#\n",
    "# ------------ create & call jit constraint -----------\n",
    "# Now that we have the python-ish inputs set up,\n",
    "# create a jit constraint function of simplified signature\n",
    "#\n",
    "mkdo_pts = mk_clustering_pts(pts, cluster_lists, springs, lr=lr, mindist=mindist)\n",
    "\n",
    "# and just invoke it as\n",
    "mkdo_pts(pts)  # simplified call signature, other args are now mk_FOO locals\n",
    "#    without re-supplying all the args like\n",
    "#        do_clustering_pts_py(pts, cluster_lists, springs, lr=lr, mindist=0.2)\n",
    "\n",
    "#\n",
    "# ------------- output --------------------------------\n",
    "# check we got the same \"output\" (in-place modification of our pts array)\n",
    "#\n",
    "print(\"final positions (one epoch)\")\n",
    "for i in range(pts.shape[0]):\n",
    "    print(f\"{i=} pt = {pts[i,:]}\")\n",
    "\n",
    "try:\n",
    "    pts_ref\n",
    "    assert np.allclose(pts, pts_ref)\n",
    "    print(\"Good: matched pts_ref\")\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(\"Goodbye!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miru] *",
   "language": "python",
   "name": "conda-env-miru-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
