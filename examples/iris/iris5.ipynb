{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog\n",
    "### URL [github UMAP fork](https://github.com/kruus/umap)\n",
    "use branch **constraints**\n",
    "\n",
    "### pin_mask demo\n",
    "- We get a $1^{st}$ embedding (using random init)\n",
    "- linearly transform so \"good\" and \"bad\" samples so their x values end up at [-1,+1]\n",
    "    - (in least-squares sense)\n",
    "- then re-embed \"pinning\" those x values *exactly* at -1, +1\n",
    "    - (could random-init by-hand, then fix x values for single pin_mask umap fit)\n",
    "- umap applies no gradient (but does apply rescaling)\n",
    "- we determine the new linear rescaling\n",
    "- and remap the embedding back to good|bad x-values -1|+1\n",
    "\n",
    "### New\n",
    "- We select a good/bad entry based on feature 0 \"sepal length\"\n",
    "  for each iris species.  Lowest pinned to x=-1, highest pinned to x=+1\n",
    "  \n",
    "  \n",
    "- still perhaps better to ROTATE (see Kabsch algorithm) the initial embedding\n",
    "  such that good|bad points are aligned *towards* (-1,0)|(+1,0) idealized drag\n",
    "  positions\n",
    "   - then rescale and shift to put their x-centroids exactly at (-1,0)|(+1,0)\n",
    "- Now we rotate, scale & shift\n",
    "- TODO: option to **shear** instead of orthogonally rotate\n",
    "\n",
    "#### behavior is not (completely) *as expected*!\n",
    "- Still no *constraint* of having unpinned points having x-values between (-1,+1)\n",
    "\n",
    "### drag-n-drop & high-D embedding\n",
    "The current approach embeds high-D euclidean to low-D euclidean.  However, the drag'n'drop *user interest* was generated from a single high-D feature.\n",
    "\n",
    "#### What rotation of high-D space, when projected onto the first 2 dims, best matches the dragged points?\n",
    "- i.e. align 1st PCA component of the dragged point data with x axis.\n",
    "   - 2nd one would be some randomish projection (ok, user doesn't really care about *y* yet,\n",
    "     except that it should yield \"some\" separation in lo-D space\n",
    "- a weighted-Euclidean metric (in the rotated hi-D space) might work nicely.\n",
    "- but no dims should get *zero* weight\n",
    "   - to avoid catastropic info loss\n",
    "   - so 'y' axis still allows separation of individual items\n",
    "   - (do not want all items to appear on single left-right line\n",
    "\n",
    "### NEW: UMAP-constraints\n",
    "- added a 'TRIAL' code blocks into layouts.py to test dimension-wise clipping bound\n",
    "- clipping bounds for *x* must be -10,+10 so that spectral init is not fubar.\n",
    "- *GOOD*: final embedding now does have *unpinned points* \"on the inside\"\n",
    "\n",
    "### NEW: add hover tool to inspect bokeh embedding (and data) values\n",
    "\n",
    "### NEW: show user-points adding a new dimension.\n",
    "Here a new user x-axis supplements the original embedding, which is now in yz-plane.\n",
    "Pinned points are at x=+/-10, while all others are initialized at x=0.\n",
    "UMAP is run to generate a 3-D embedding, pulling \"neighbors\" away from the x=0 plane\n",
    "The yz-axes of the 3-D UMAP embedding can then be reprojected back into 2-D, such that\n",
    "the x-axis still reflects good/bad user info.\n",
    "\n",
    "### NEW: **(deprecated)** add a user-passible `constraint` object (default=None) to UMAP.\n",
    "- or actually, a list of constraint objects\n",
    "- `constraint.project_onto_constraint( low_embedding_vector )` may do an\n",
    "  in-place modification of `low_embedding_vector`\n",
    "- layouts.py has a `jitclass` called `DimLohi` example of a clipping constraint\n",
    "- other constraint types might project the full data set (during/post-epoch?),\n",
    "  perhaps like `DimLoHi:project_rows_onto_constraint(self, mat)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html\n",
    "<style>\n",
    "<!-- table {float:left} -->\n",
    "    table {display: inline-block}\n",
    "</style>\n",
    "<style>\n",
    "    /* Jupyter */\n",
    "    .rendered_html table,\n",
    "    /* Jupyter Lab*/\n",
    "    div[data-mime-type=\"text-markdown\"] table {\n",
    "        margin-left: 0\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW: UMAP-constraints supports user-defined constraints\n",
    "Original UMAP fork supported only a 'pin_mask' array argument.\n",
    "Now general constraints are numba JIT functions passed into:\n",
    "\n",
    "- the UMAP constructor (for dataset-independent constraints on points/gradients)\n",
    "- or the UMAP fitting routine (for dataset-dependent constrains, like pinning certain\n",
    "  points\n",
    "  \n",
    "These user constraint function get applied at appropriate times during the\n",
    "gradient descent phase of UMAP to beef up the usual UMAP \"forces\" that adjust\n",
    "positions of the lo-D embedded points.\n",
    "\n",
    "umap-constraints/umap/constraints2.py contains several examples.\n",
    "\n",
    "- umap always passes point and grad info, that the constraint modifies **in-place**\n",
    "- user-supplied *extra* constraint parameters are passed as a tuple of constraint_kwds\n",
    "\n",
    "The class methods become function name suffixes:\n",
    "---------------------------------------------------\n",
    "class method (old way)          |  suffix | args\n",
    "------------------------------- | ------- | ----\n",
    "project_onto_constraint         | \\_pt    | idx, pt\n",
    "project_rows_onto_constraint    | \\_pts   | pts\n",
    "project_onto_tangent_space      | \\_grad  | idx, pt, grad\n",
    "project_rows_onto_tangent_space | \\_grads | pts, grads\n",
    "(maybe) fit_onto_constraint     | \\_fit   | pts (?)\n",
    "---------------------------------------------------\n",
    "\n",
    "for dataset-agnostic projectors (supplied to UMAP constructor) the\n",
    "'idx' argument is dropped.\n",
    "\n",
    "Constraint varieties demo'ed in constraints2.py:\n",
    "- **dimlohi**: bound selected pt(s) dimension-wise in (lo,hi)\n",
    "    - this is a hard constraint only -- no gradient version\n",
    "- **pinindexed**: pin a subset of points (pin_idx) to fixed positions (pin_pos)\n",
    "    - the gradient version assumes all pins have been applied, and\n",
    "      sets the gradient of pinned points to zero, so they stay put.\n",
    "- **freeinf**: given array infs\\[npts, loD\\], copy any non-inf values in infs\n",
    "  into the pt(s) coordinates\n",
    "    - gradient update variety zeros the gradients of the infs (point,coord) array\n",
    "- **springindexed**: given vectors of pin_idx, pin_pos, springs, pt(s) or gradient(s)\n",
    "  of all points pin_idx\\[i\\] move:\n",
    "    - \\_pt\\[s\\] with infinite springs\\[i\\] constant move all the way to their pin_pos\\[i\\] vector\n",
    "    - \\_grad\\[s\\] forces are modified with springs\\[i\\] pulling towards pin_pos\\[i\\]\n",
    "        - using class $F=-kr^2$ spring force.  $k$ is the \"spring constant\".\n",
    "    - (This can be abused for clustering, but multiple or overlapped clusters might\n",
    "       be difficult to control)\n",
    "    - Ideas:\n",
    "        - pin_pos could be a constant vector (same for all pin_idx)\n",
    "        - springs can be scalars (auto-broadcast, again)\n",
    "        - pin_pos None could pin to center-of-mass.\n",
    "\n",
    "### Constraint TODO:\n",
    "- demo *springindexed* is really only great for a single cluster!\n",
    "    - multiple *springindexed* living as a **set** of cluster descriptions. \n",
    "  \n",
    "### *LATER*: see if UMAP can crudely be simulated by spring & dashpot physics\n",
    "- *springs* : equilibrium distances and force constants\n",
    "- *dashpots* : motion damping proportional to velocity\n",
    "\n",
    "Why? such force fields can be quickly done client side, all in the low-dim embedding space.\n",
    "\n",
    "Init via nearest-neighbors + random sample of distant neighbors\n",
    "Fine-tuning might double-check points with \"too-large\" force-gradient\n",
    "and add some small number of careful long-distance springs that best reduce this.\n",
    "\n",
    "- Approximating force-field would be generated server-side.\n",
    "- Client drag-n-drop uses approx force field (perhaps with some expanded *user dims*)\n",
    "- State is preserved after rerunning umap? Or is it better to save the spring model\n",
    "  and let the user decide when to run a full UMAP recalc (with new drag constraints etc.)\n",
    "\n",
    "Shorter distance ~ higher spring constant; longer ~ weak spring constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import CategoricalColorMapper, ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Category10, Colorblind, Viridis, Viridis256\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.io import output_notebook, export_png\n",
    "from bokeh.layouts import column, gridplot\n",
    "output_notebook()\n",
    "\n",
    "import umap\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Note: bokeh export_png requires 'conda install selenium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "# from earlier 'jitclass' version\n",
    "#umap.constraints.test_HardPinIndexed()\n",
    "#umap.constraints.test_SoftPinIndexed()\n",
    "#umap.constraints.test_DimLohi()\n",
    "# dumb numba function api\n",
    "umap.constraints.test_dimlohi()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(iris))\n",
    "print(type(iris.data))\n",
    "print(iris.data.shape, iris.data[0:5,])\n",
    "print(iris.target.shape, iris.target[0:5])\n",
    "print(iris.target_names.size, iris.target_names)\n",
    "print(len(iris.feature_names), iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm interested in feature 0 (sepal length) really small.\n",
    "feature_of_interest = 0\n",
    "fi_name = iris.feature_names[feature_of_interest]\n",
    "di = data_of_interest = iris.data[:,feature_of_interest]\n",
    "if True:\n",
    "    # This time, choose good/bad from each iris species\n",
    "    nFeat = iris.target_names.size\n",
    "    good10 = np.zeros(nFeat,dtype=np.int32)\n",
    "    bad10 = np.zeros(nFeat,dtype=np.int32)\n",
    "    for t,name in enumerate(iris.target_names):\n",
    "        print(t,name)\n",
    "        mask = (iris.target==t)\n",
    "        #print(di[mask])\n",
    "        dilo = np.argmin(di[mask]) # index within masked group\n",
    "        dihi = np.argmax(di[mask])\n",
    "        #print(dilo)\n",
    "        diilo = np.arange(di.shape[0]) [mask] [dilo] # index within original\n",
    "        diihi = np.arange(di.shape[0]) [mask] [dihi]\n",
    "        #print(diilo)\n",
    "        good10[t] = diilo\n",
    "        bad10[t] = diihi\n",
    "\n",
    "    print(\"\\nSelected shortest (good) and longest (bad)\",\n",
    "          fi_name, \"of each iris species\")\n",
    "    print(fi_name, \"good/bad values:\")\n",
    "    row_names = [\"good\", \"bad\"]\n",
    "    col_names = iris.target_names\n",
    "    matrix = np.zeros((2,3))\n",
    "    for t,name in enumerate(col_names):\n",
    "        matrix[0,t] = iris.data[ good10[t], feature_of_interest ]\n",
    "        matrix[1,t] = iris.data[ bad10[t], feature_of_interest ]\n",
    "    df = pd.DataFrame(matrix, columns=col_names, index=row_names)\n",
    "    print(df)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n",
    "if False: # older case\n",
    "    # choose 2 \"interesting\" examples and 2 uninteresting\n",
    "    nFeat = 4\n",
    "    print(\"feature_of_interest\",feature_of_interest)\n",
    "    best = np.argmin(data_of_interest)\n",
    "    #good3 = np.argpartition(iris.data[:,0], 3)\n",
    "    #print(\"good\",good, \"good3\",good3)\n",
    "    #print(iris.data[good3,])\n",
    "    goods = np.argsort(data_of_interest)\n",
    "    good10 = goods[0:nFeat]\n",
    "    bad10 = goods[-nFeat:,]\n",
    "\n",
    "print(\"good10\",good10,\"\\ndata of goods:\\n\",iris.data[good10,])\n",
    "print(\"bad10\",bad10,  \"\\ndata of bads:\\n\",iris.data[bad10])\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP (no constraints yet)\n",
    "- This demo is *atypical* in that the original data has *few* (4) dimensions\n",
    "    - It is mostly to demo and test the invasive changes to UMAP-constrain\n",
    "    - For images or text, hi-D embedding may have 32 to thousands or more dimensions.\n",
    "- UMAP (t-SNE, pyMDE) *conceptually* matches a hi-D weighted graph to a counterpart in lo-D\n",
    "    - n.n. in hi-D should remain n.n. in lo-D, ...\n",
    "\n",
    "- In hi-D, *local intrinsic dimension* typically remains low, even as dimensionality increases.\n",
    "- So you can imagine *real data* populating \"ribbons\" in hi-D space\n",
    "  - i.e. if \\# of points in a ball of radius r scales as $r^{N-1}$ around some point,\n",
    "    real data roughly lies on an N-dimensional ribbon.\n",
    "    (Often N is in 8-16 range, but sometimes up to 40)\n",
    "  - Picture the hi-D space filled with such \"ribbons\" of probability density.\n",
    "  - Often you can see UMAP/tSNE mapping these ribbons onto line-like features\n",
    "    when visualized in 2-D plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can UMAP do an identity map?\n",
    "The next cell shows that if there is no dimension reduction,\n",
    "even with enough points constrained not to move,\n",
    "UMAP still does adjust some points by a large distance.\n",
    "\n",
    "I am not recovering an identity map.  I guess the question is\n",
    "whether the shape \"behaves significantly differently\" !\n",
    "\n",
    "I suppose that UMAP is \"spreading out\" the unconstrained points (since it can).\n",
    "Even with densmap, the UMAP is not doing an identity mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental ... no dimension reduction\n",
    "print(iris.data.shape)\n",
    "##%%writefile iris4-emb-init.log\n",
    "##%%capture iris4-emb-init.log\n",
    "init0 = iris.data.copy().astype(np.float32)\n",
    "print(init0[0])\n",
    "print(init0[10:15])\n",
    "fix0 = np.ones((iris.data.shape[0]), dtype=np.int32)\n",
    "fix0[good10] = 0.0\n",
    "fix0[bad10] = 0.0\n",
    "fix0[100] = 0.0\n",
    "fix0[120] = 0.0\n",
    "fix0[130] = 0.0\n",
    "fix0[0] = fix0[1] = 0.0\n",
    "print(\"fix0.shape\",fix0.ndim, fix0.shape, fix0.shape[0], \" init0.shape\",init0.shape)\n",
    "print(fix0[10:15])\n",
    "\n",
    "#init_random_state = None  # this allows parallel umap lo-D embedding optimization\n",
    "init_random_state = 12345 # this will force single-threaded (more reproducible)\n",
    "\n",
    "emb0 = umap.UMAP( min_dist=0.001,\n",
    "    n_neighbors=30, learning_rate=1e-2, random_state=init_random_state,\n",
    "    init = init0, #densmap=True,\n",
    "    n_components = iris.data.shape[1],\n",
    ").fit_transform(iris.data, data_constrain = fix0)\n",
    "print(iris.data[0], emb0[0])\n",
    "print(init0[good10], \"\\n\", emb0[good10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmoved = np.sqrt(np.sum(np.square(emb0 - init0), axis=1))\n",
    "print(distmoved.shape,distmoved[0:5])\n",
    "av_distmoved = np.sum(distmoved)*(1.0/distmoved.shape[0])\n",
    "print(\"avg distance moved:\", av_distmoved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##%%writefile iris4-emb-init.log\n",
    "##%%capture iris4-emb-init.log\n",
    "umapper50 = umap.UMAP(\n",
    "    n_neighbors=50, learning_rate=0.5, random_state=init_random_state, init=\"random\", min_dist=0.001,\n",
    ")\n",
    "embedding = umapper50.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding[0:15,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file(\"iris2a.html\")\n",
    "\n",
    "targets = [str(d) for d in iris.target_names]\n",
    "targets += [\"good\",\"bad\"]\n",
    "source = ColumnDataSource(\n",
    "    data = dict(\n",
    "        x0=embedding[:,0],\n",
    "        y0=embedding[:,1],\n",
    "        #g=[i in good10 for e,i in enumerate(embedding) # ?\n",
    "        #b=[i in bad10  for i in range(embedding.shape[0])] # equiv for bad ?\n",
    "        label=[targets[d] for d in iris.target],\n",
    "    )\n",
    ")\n",
    "#for i in range(len(iris.feature_names)\n",
    "#    source.data[iris.feature_names[i]] = iris.data[i,]\n",
    "# 4 ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "source.data[\"Sepal_Length\"] = iris.data[:,0]\n",
    "source.data[\"Sepal_Width\"]  = iris.data[:,1]\n",
    "source.data[\"Petal_Length\"] = iris.data[:,2]\n",
    "source.data[\"Petal_Width\"]  = iris.data[:,3]\n",
    "tooltips = [\n",
    "    (\"(x,y)\",  \"(@x0,@y0)\"),   # tooltips[1] can be modified in later plots\n",
    "    (\"Iris Sample\", \"$index: @label\"),\n",
    "    (\"Sepal Length,Width\", \"@Sepal_Length{0.0}, @Sepal_Width{0.0}\"),\n",
    "    (\"Petal Length,Width\", \"@Petal_Length{0.0}, @Petal_Width{0.0}\"),\n",
    "]\n",
    "#print(tooltips[0])\n",
    "\n",
    "cmap = CategoricalColorMapper(factors=targets, palette=Category10[10])\n",
    "\n",
    "p1 = figure(title=\"Test UMAP on Iris dataset\",\n",
    "            tooltips=tooltips)\n",
    "circles = p1.circle(source=source, x=\"x0\", y=\"y0\",\n",
    "    size=8, fill_alpha=0.5,\n",
    "    color={\"field\": \"label\", \"transform\": cmap},\n",
    "    #legend_label=\"species\",\n",
    "    legend_group=\"label\"\n",
    ")\n",
    "# tooltips are only for circles\n",
    "hover = p1.select_one(HoverTool)\n",
    "hover.renderers = [circles]\n",
    "\n",
    "# gray boxes around good/bad points and (fake) category\n",
    "gb = np.vstack([embedding[good10,], embedding[bad10,]])\n",
    "gbcat = np.hstack((np.repeat(\"good\",nFeat), np.repeat(\"bad\",nFeat)))\n",
    "gbsource = ColumnDataSource( dict(\n",
    "        x0 = gb[:,0],\n",
    "        y0 = gb[:,1],\n",
    "        label = gbcat,\n",
    "    ))\n",
    "p1.square(source=gbsource, x=\"x0\", y=\"y0\",\n",
    "          size=16, line_alpha=0.7, line_width=4, fill_alpha=0.0,\n",
    "          color={\"field\": \"label\", \"transform\": cmap},\n",
    "          legend_group=\"label\",\n",
    ")\n",
    "#p1.add_layout(p1.legend[0], 'right') # outside, plot rectangular!\n",
    "#p1.legend.location = 'top_left'\n",
    "#p1.legend.location = 'top_right'\n",
    "p1.legend.location = 'center_center'\n",
    "\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"good10:\\n\", embedding[good10,])\n",
    "print(\"bad10:\\n\",  embedding[bad10,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create user arguments for some simple constraint functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{embedding.shape=}\")\n",
    "pin_idx = np.concatenate( (good10, bad10) );\n",
    "print(f\"{pin_idx=}\\n\")\n",
    "\n",
    "# hard pins : good10 moved 95% of the way to [+3,0]; bad10, to [-3,0]\n",
    "print(\"\\n*** hard pins moving 95% of way to [+/-3, 0]\")\n",
    "gpos = embedding[good10,]\n",
    "gpin = np.ndarray(gpos.shape); gpin[:,] = [3.0,0.0]\n",
    "gpin = 0.95 * gpin + 0.05 * gpos\n",
    "bpos = embedding[bad10,]\n",
    "bpin = np.ndarray(bpos.shape); bpin[:,] = [-3.0, 0.0]\n",
    "bpin = 0.95 * bpin + 0.05 * bpos\n",
    "pin_idx1 = np.concatenate( (good10,bad10) )\n",
    "pin_pos1 = np.concatenate( (gpin, bpin) )\n",
    "# using the _pts constraints type is more efficient, and we don't need\n",
    "# sorting pin pin_idx|pos to use binary search in the constraint function.\n",
    "print(f\"{pin_idx1=}\")\n",
    "print(f\"{pin_pos1=}\")\n",
    "\n",
    "# hard pins : good10 \"scaled\" (quick'n'dirty) into unit ball at [+3,0]; bad10, to [-3,0]\n",
    "print(\"\\n*** hard pins scaling into unit balls around [+/-3, 0]\")\n",
    "gpos = embedding[good10,]\n",
    "gpin = np.ndarray(gpos.shape); gpin[:,] = [3.0,0.0]\n",
    "gvec = gpin - gpos\n",
    "print(f\"{gvec=}\")\n",
    "gmag = np.linalg.norm(gvec,axis=1)\n",
    "#print(f\"{gmag=}\")\n",
    "#gnorm = gvec[:,]/gmag[:,None]\n",
    "#print(f\"{gnorm=}\")\n",
    "#print(f\"check norm? {np.linalg.norm(gnorm, axis=1)=}\") # yes it's all 1.0\n",
    "gradial = 1.0 - np.exp(-0.1 * gmag)\n",
    "print(f\"{gradial=}\")\n",
    "gpin = gpin + gradial[:,None] * (-gvec[:,] / gmag[:,None])\n",
    "#gpin = 0.95 * gpin + 0.05 * gpos\n",
    "bpos = embedding[bad10,]\n",
    "bpin = np.ndarray(bpos.shape); bpin[:,] = [-3.0, 0.0]\n",
    "bvec = bpin - bpos\n",
    "bmag = np.linalg.norm(bvec,axis=1)\n",
    "bradial = 1.0 - np.exp(-0.1 * bmag)\n",
    "bpin = bpin + bradial[:,None] * (-bvec[:,] / bmag[:,None])\n",
    "pin_idx2 = np.concatenate( (good10,bad10) )\n",
    "pin_pos2 = np.concatenate( (gpin, bpin) )\n",
    "print(f\"{pin_idx2=}\")\n",
    "print(f\"{pin_pos2=}\")\n",
    "\n",
    "print(\"\\n*** soft springs pulling towards [+/-3, 0]\")\n",
    "# add a small spring on all 6 points towards [+/- 1, 0]\n",
    "#pin_idx = np.ndarray( (good10.size+bad10.size, 2), dtype=np.float32 )\n",
    "#print(pin_idx.shape)\n",
    "print(f\"{good10=}\")\n",
    "print(f\"{bad10=}\")\n",
    "pin_idx2 = np.concatenate( (good10,bad10) )\n",
    "pin_pos3 = np.zeros( (good10.size+bad10.size, embedding.shape[1]), dtype = np.float32 )\n",
    "pin_pos3[ 0:good10.size, 0 ] = +3.0\n",
    "pin_pos3[ good10.size:, 0 ] = -3.0\n",
    "springs3 = np.full( good10.size+bad10.size, 2.0, dtype=np.float32 ) # spring constant k = 2.0; Force = -kr^2\n",
    "print(f\"{pin_idx2=}\")\n",
    "print(f\"{pin_pos3=}\\n\")\n",
    "print(f\"{springs3=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### point cloud \"best-match\" transforms\n",
    "Here are a few simple ways to adapt a point cloud to user inputs.\n",
    "\n",
    "Ex. 1 points pulled in lo-D space --> simple point-cloud transform that gives good match.\n",
    "More points:  \"best-fit\" transform\n",
    "\n",
    "UMAP embedding with Euclidean lo-D distance is \"just as good\" under globally-scaled,\n",
    "rigid-body transforms.   Such transforms can be done quickly (even client-side) and\n",
    "can serve as a decent initialization to re-adjust the UMAP fitting (maybe 1/2 epochs\n",
    "of gradient descent).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate drag'n'drop of goods to left, bads to right\n",
    "\n",
    "print(\"good10:\\n\",  embedding[good10,])\n",
    "print(\"bad10:\\n\",   embedding[bad10,])# simulate drag'n'drop of goods to left, bads to right\n",
    "method_names=[\"force\", \"linear\", \"rot,scale,trans\"]\n",
    "\n",
    "method=2 #rotate-scale-translate\n",
    "\n",
    "#\n",
    "# method 1: \"best\" linear transform of x-coords of embedding\n",
    "#\n",
    "# y = [e 1] @ [m c] st. e'[good10,][0] ~ -1 and e'[bad10,][0] ~ 1\n",
    "def emb_linear(emb0, emb1, pt0, pt1, coord=0 ):\n",
    "    \"\"\" shift emb0, emb1 towards goals t0, t1 returning mx+c that best shifts x (axis=0) values \"\"\"\n",
    "    e = np.hstack((emb0[:,coord], emb1[:,coord]))\n",
    "    # hoping for first half ~ -1, rest ~ +1\n",
    "    y = np.hstack((np.repeat(pt0[coord],emb0.shape[0]), np.repeat(pt1[coord],emb1.shape[0])))\n",
    "    print(type(e), type(y), e.shape, y.shape)\n",
    "    assert( e.size == y.size )\n",
    "    A = np.vstack([e, np.ones(len(e))]).T  # add a one's column\n",
    "    print(type(A), A.shape, \"\\n\")\n",
    "    print(\"A\", A)\n",
    "    print(\"y\", y)\n",
    "\n",
    "    #x, residuals, rank, s = np.linalg.lstsq(A, y, rcond=None)\n",
    "    #print(\"lstsq -> x=\",x)\n",
    "    #m,c = x\n",
    "    m,c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    print(\"m,c\",np.round(m,3),np.round(c,3))\n",
    "    print(\"fit\",m*e+c)\n",
    "    return [m, c]\n",
    "\n",
    "def emb_linear_apply(x, embedding):\n",
    "    m = x[0]\n",
    "    c = x[1]\n",
    "    emb2 = embedding\n",
    "    # re-embed all data w/ \"best\" linear transform of 'x' values\n",
    "    # rescale 'y' too, (keep rel. distances, don't care about y shift)\n",
    "    emb2[:,0] = m * embedding[:,0] + c\n",
    "    emb2[:,1] = m * embedding[:,1]\n",
    "    emb2[:,1] -= np.average(emb2, axis=1) # 'y' centroid --> zeroprint(\"good10:\\n\", embedding[good10,])\n",
    "    return embedding\n",
    "\n",
    "def opa(a, b):\n",
    "    \"\"\" return rot, scale, translation, and rmsd of shifting `b` to concord with `a`.\n",
    "    \n",
    "    `a` and `b` are N D-dim vectors.\n",
    "    \n",
    "    Suppose we return r, s, t, d.\n",
    "    \n",
    "    To apply the recovered transform to other M D-dim vectors X, calculate\n",
    "    `X.dot(r) * s + t`\n",
    "    \"\"\"\n",
    "    assert( a.shape == b.shape )\n",
    "    aT = a.mean(0)\n",
    "    bT = b.mean(0)\n",
    "    A = a - aT \n",
    "    B = b - bT\n",
    "    aS = np.sum(A * A)**.5\n",
    "    bS = np.sum(B * B)**.5\n",
    "    A /= aS\n",
    "    B /= bS\n",
    "    U, _, V = np.linalg.svd(np.dot(B.T, A))\n",
    "    aR = np.dot(U, V)\n",
    "    if np.linalg.det(aR) < 0:\n",
    "        V[1] *= -1\n",
    "        aR = np.dot(U, V)\n",
    "    aS = aS / bS\n",
    "    aT-= (bT.dot(aR) * aS)\n",
    "    # the original only returned a rotation-only \"rms\"... between scaled+translated points\n",
    "    aD = (np.sum((A - B.dot(aR))**2) / len(a))**.5\n",
    "    # the xform in general is : a[1] = a[1].dot(r) * s + t\n",
    "    # if we actually DO the full transform \"LONG HAND\"\n",
    "    #aD = np.sqrt(((a - (b.dot(aR) * aS + aT))**2).sum() / len(a))\n",
    "    # equivalently, include scaling into previous rmsd as\n",
    "    aD *= (aS * bS)\n",
    "    return aR, aS, aT, aD \n",
    "        \n",
    "def emb_opa(emb0, emb1, pt0, pt1, coord=0):\n",
    "    \"\"\" rotate,scale,translate s.t. coord of emb0,emb1 somewhat match 2 points pt0,pt1.\"\"\"\n",
    "    print(len(pt0), emb0.shape)\n",
    "    D = emb0.shape[1]\n",
    "    assert( len(pt0) == D ) # emb0 and pt0 are both D-dim\n",
    "    assert( emb1.shape[1] == D )\n",
    "    assert( len(pt1) == D )\n",
    "    e = np.vstack((emb0, emb1))\n",
    "    print(e.shape, e)\n",
    "    # hoping for first half ~ -1, rest ~ +1\n",
    "    # if pt0,pt1 were scalar target values for a single coord...\n",
    "    #y = np.zeros_like(e)\n",
    "    #y[:,coord] = np.hstack((np.repeat(pt0,emb0.shape[0]), np.repeat(pt1,emb1.shape[0])))\n",
    "    #print(\"y[,feat]\",y[:,feature_of_interest])\n",
    "    # if pt0,pt1 are D-dim target points for each class emb0/emb1\n",
    "    y = np.repeat( np.vstack((pt0,pt1)), [emb0.shape[0],emb1.shape[0]], axis=0 )\n",
    "    print(y.shape, y)\n",
    "    \n",
    "    print(type(e), type(y), e.shape, y.shape)\n",
    "    assert( e.size == y.size )\n",
    "    #r,s,t,d = opa(y,e)\n",
    "    return opa(y,e)\n",
    "def emb_opa_apply(x, embedding):\n",
    "    \"\"\" given x=[r,s,t,d]\"\"\"\n",
    "    return embedding.dot(x[0]) * x[1] + x[2]\n",
    "\n",
    "#\n",
    "# method 0: naive, brute force\n",
    "#\n",
    "if method==0:\n",
    "    emb2 = embedding\n",
    "    emb2[good10,0] = -10.0\n",
    "    emb2[bad10,0] = +10.0\n",
    "    # --- without clamping, we totally lose the \"init\" state\n",
    "\n",
    "#\n",
    "# method 1: \"best\" linear transform of x-coords of embedding\n",
    "#\n",
    "if method==1:\n",
    "    print(\"good10:\\n\",  embedding[good10,])\n",
    "    print(\"bad10:\\n\",  embedding[bad10,])\n",
    "    x = emb_linear( embedding[good10,], embedding[bad10,], [-10,0], [10,0] )\n",
    "    print(\"x\", x)\n",
    "    emb2 = emb_linear_applyly( x, embedding)\n",
    "\n",
    "#\n",
    "# method 2: \"best\" rotate, scale and translate\n",
    "#\n",
    "if method==2:\n",
    "    x = emb_opa( embedding[good10,], embedding[bad10,], [-10,0], [10,0] )\n",
    "    print(\"x\", x)\n",
    "    emb2 = emb_opa_apply( x, embedding)\n",
    "\n",
    "print(\"UMAP pinning init method\", method_names[method])\n",
    "print(\"emb2 pinning init good10:\\n\",  emb2[good10,])\n",
    "print(\"emb2 pinning init bad10:\\n\",  emb2[bad10,])\n",
    "#embedding = emb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot emb2\n",
    "def plot_emb(emb, title):\n",
    "    # Modify existing ColumnDataSources\n",
    "    targets = [str(d) for d in iris.target_names]\n",
    "    targets += [\"good\",\"bad\"]\n",
    "    source = ColumnDataSource(\n",
    "        data = dict(\n",
    "            x0=embedding[:,0],\n",
    "            y0=embedding[:,1],\n",
    "            #g=[i in good10 for e,i in enumerate(embedding) # ?\n",
    "            #b=[i in bad10  for i in range(embedding.shape[0])] # equiv for bad ?\n",
    "            label=[targets[d] for d in iris.target],\n",
    "        )\n",
    "    )\n",
    "    #for i in range(len(iris.feature_names)\n",
    "    #    source.data[iris.feature_names[i]] = iris.data[i,]\n",
    "    # 4 ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "    source.data[\"Sepal_Length\"] = iris.data[:,0]\n",
    "    source.data[\"Sepal_Width\"]  = iris.data[:,1]\n",
    "    source.data[\"Petal_Length\"] = iris.data[:,2]\n",
    "    source.data[\"Petal_Width\"]  = iris.data[:,3]\n",
    "    source.data[\"x2\"] = emb[:,0]\n",
    "    source.data[\"y2\"] = emb[:,1]\n",
    "    tooltips = [\n",
    "        (\"(x,y)\",  \"(@x0,@y0)\"),   # tooltips[1] can be modified in later plots\n",
    "        (\"Iris Sample\", \"$index: @label\"),\n",
    "        (\"Sepal Length,Width\", \"@Sepal_Length{0.0}, @Sepal_Width{0.0}\"),\n",
    "        (\"Petal Length,Width\", \"@Petal_Length{0.0}, @Petal_Width{0.0}\"),\n",
    "    ]\n",
    "    tooltips[0] = (\"(x,y)\",  \"(@x2,@y2)\")\n",
    "    \n",
    "    # gray boxes around good/bad points and (fake) category\n",
    "    # bugfix: gbsource MUST be local variables.\n",
    "    gb = np.vstack([emb[good10,], emb[bad10,]])\n",
    "    gbcat = np.hstack((np.repeat(\"good\",nFeat), np.repeat(\"bad\",nFeat)))\n",
    "    gbsource = ColumnDataSource( dict(\n",
    "            x0 = gb[:,0],\n",
    "            y0 = gb[:,1],\n",
    "            label = gbcat,\n",
    "        ))\n",
    "    gbsource.data[\"x2\"] = gb[:,0]\n",
    "    gbsource.data[\"y2\"] = gb[:,1]\n",
    "    #print(tooltips)\n",
    "    #cmap = CategoricalColorMapper(factors=targets, palette=Category10[10])\n",
    "\n",
    "    embplot = figure(title=title, tooltips=tooltips)\n",
    "    circles = embplot.circle( source=source, x=\"x2\", y=\"y2\",\n",
    "        size=8, fill_alpha=0.5,\n",
    "        color={\"field\": \"label\", \"transform\": cmap},\n",
    "        legend_group=\"label\"\n",
    "    )\n",
    "    hover = embplot.select_one(HoverTool)\n",
    "    hover.renderers = [circles]\n",
    "\n",
    "    embplot.square(source=gbsource, x=\"x2\", y=\"y2\",\n",
    "              size=16, line_alpha=0.7, line_width=4, fill_alpha=0.0,\n",
    "              color={\"field\": \"label\", \"transform\": cmap},\n",
    "              legend_group=\"label\"\n",
    "    )\n",
    "    #embplot.legend.location = 'top_right'\n",
    "    embplot.legend.location = 'top_left'\n",
    "    #embplot.legend.location = 'center_center'\n",
    "    return embplot\n",
    "\n",
    "emb2_title=(\"Iris \"+method_names[method]+\" drag'n'drop init, emb2\")\n",
    "p2 = plot_emb(emb2,emb2_title)\n",
    "show(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP-constraints\n",
    "Rotate-scale-translate has has **not** yet mucked about with the lo-D embedding metric\n",
    "in any serious fashion.  All relative distances are unchanged.\n",
    "\n",
    "Now we rerun UMAP, satisfying 2 types of constraint:\n",
    "\n",
    "1. **Normal UMAP constraints** force the hi-D manifold (represented as a fuzzy simplicial complex\n",
    "   ~ weighted connectivity graph) to match the lo-D Euclidean distances.\n",
    "\n",
    "1. The lo-D points are forced to satisfy **visualization constraints** (user drag'n'drop)\n",
    "\n",
    "This happens by modifying points or gradients (or both) during the gradient descent phase of\n",
    "generating the lo-D embedding.\n",
    "\n",
    "This generates a new metric in the lo-D space.  UMAP provides translation from hi-D to lo-D space\n",
    "of arbitrary points.  So implicitly one *could* port this distance measure back into the hi-D space.\n",
    "One could also generate new diffusion-based metrics based on the graph structure.  You can think\n",
    "of these as sort of robust estimates of shortest path, given a lo-D connectivity graph.\n",
    "\n",
    "In what follows, we choose to apply the user constraints in the same space as the 2-D visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinned UMAP (and undo UMAP internal rescaling)\n",
    "emb3 = emb2.copy()\n",
    "emb3[good10,0] = -10\n",
    "emb3[bad10,0]  = +10\n",
    "print(\"embedding.shape\",emb3.shape)\n",
    "print(\"good10:\\n\", emb3[good10,])\n",
    "print(\"bad10:\\n\",  emb3[bad10,])# re-embed just with new init conditions\n",
    "pin_mask = np.ones(emb3.shape, dtype=np.float32) # todo: allow float32\n",
    "pin_mask[good10,0] = 0.0 # zero gradient, so zero 'x' movement of init embedding\n",
    "pin_mask[bad10,0] = 0.0\n",
    "print(\"type(pin_mask)\",type(pin_mask), isinstance(pin_mask, np.ndarray))\n",
    "for i in range(pin_mask.shape[0]):\n",
    "    if np.any(pin_mask[i,] == 0.0):\n",
    "        print(\"pinned sample\",i,\"pin_mask\",pin_mask[i,],\"emb3\",emb3[i,])\n",
    "print(\"pin_mask.shape\",pin_mask.shape)\n",
    "print(\"pin_mask good10:\\n\", pin_mask[good10,])\n",
    "print(\"pin_mask bad10:\\n\",  pin_mask[bad10,])# re-embed just with new init conditions\n",
    "#   NOTE: should have pin_mask in UMAP constructor !\n",
    "\n",
    "# Also constrain first point:\n",
    "pin_mask[0,:] = 0.0\n",
    "\n",
    "# test a constraint version:\n",
    "### the class-based constraints were removed (numba jitclass support was not really enough)\n",
    "#pni = umap.constraints.PinNoninf(np.where( pin_mask==0, emb3, np.inf ).astype(np.float32))\n",
    "#a = pni.project_rows_onto_constraint( emb2.copy() )\n",
    "#assert np.all(a == emb3)\n",
    "#grad = emb2.copy().astype(np.float32)\n",
    "#data = 0.1*a # don't care\n",
    "#grad = pni.project_rows_onto_tangent_space(data, grad) # pinned grads should come back as zero\n",
    "#assert np.all(grad[good10,0] == 0.0)\n",
    "#assert np.all(grad[bad10, 0] == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%writefile iris4-reemb.log\n",
    "print(\"init=emb3 good10:\\n\", emb3[good10,])\n",
    "print(\"init=emb3 bad10:\\n\",  emb3[bad10,])# re-embed just with new init conditions\n",
    "embedder3 = umap.UMAP(\n",
    "    n_neighbors=50, learning_rate=0.5, random_state=init_random_state, init=emb3,\n",
    "    negative_sample_rate=5, repulsion_strength=0.40,\n",
    "    min_dist=0.001, spread=3.0,\n",
    "    #a=0.1, b=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emb3 = embedder3.fit_transform(iris.data, data_constrain=pin_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emb3[0:15,])\n",
    "print(\"pinned umap emb3 good10:\\n\", emb3[good10,])\n",
    "print(\"pinned umap emb3 bad10:\\n\",  emb3[bad10,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP has rescaled things \"behind our back\".\n",
    "# I modified UMAP to avoid the rescale if pin_mask is not None\n",
    "#    (or maybe if \"enough\" points have been pinned?)\n",
    "# There were also mods needed to avoid dimension-wise rescaling\n",
    "#    factors begin applied during 'init='\n",
    "\n",
    "# These things were \"fixed\" in my umap branch so this cell now is a no-op\n",
    "\n",
    "print(\"pinned umap good10:\\n\", emb3[good10,])\n",
    "print(\"pinned umap bad10:\\n\",  emb3[bad10,])\n",
    "\n",
    "emb4 = emb3.copy()\n",
    "if False: # old code (this coord-rescale method is actually what we want to do.)\n",
    "    # Oh-oh.  umap is doing some internal rescaling -- let's undo that.\n",
    "    goodx = emb3[good10[0],0]\n",
    "    badx  = emb3[bad10[0],0]\n",
    "    print(\"umap --> good,bad=\",goodx,badx)\n",
    "    x = np.array([goodx,badx])\n",
    "    A = np.array([[goodx,1.0],[badx,1.0]])\n",
    "    y = np.array([-1.0,1.0])\n",
    "    print(\"A\\n\",A,\"\\ny\\n\",y)\n",
    "    m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    print(\"m,c\",np.round(m,3),np.round(c,3))\n",
    "    print(\"fit\",m*x+c)\n",
    "    # scaling factor applies to BOTH x and y\n",
    "    emb4[:,0] = m*emb3[:,0] + c\n",
    "    emb4[:,1] = m*emb3[:,1]\n",
    "    emb4[:,1] -= np.average(embedding, axis=1) # 'y' centroid --> zero\n",
    "\n",
    "if False: # new: support several \"re-project\" methods\n",
    "    # This reproject should ONLY SCALE\n",
    "    rescale = 1\n",
    "    if rescale==0:\n",
    "        emb4[good10,0] = -10.0\n",
    "        emb4[bad10,0] = +10.0\n",
    "    if rescale==1: # use x-values to determine space scalings\n",
    "        print(\"good10:\\n\",  emb3[good10,])\n",
    "        print(\"bad10:\\n\",  emb3[bad10,])\n",
    "        x = emb_linear( emb3[good10,], emb3[bad10,], [-10,0], [10,0] )\n",
    "        print(\"x\", x)\n",
    "        emb4 = emb_linear_apply( x, emb3)\n",
    "    if rescale==2:\n",
    "        # rotate/scale/translate WILL NOT RE-PIN the x-values as desired!\n",
    "        x = emb_opa( emb3[good10,], emb3[bad10,], [-10,0], [10,0] )\n",
    "        print(\"x\", x)\n",
    "        emb4 = emb_opa_apply( x, emb3)\n",
    "print(\"re-shift good10:\\n\", emb4[good10,])\n",
    "print(\"re-shift bad10:\\n\",  emb4[bad10,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file(\"iris4.html\")\n",
    "\n",
    "source.data[\"x4\"] = emb4[:,0]\n",
    "source.data[\"y4\"] = emb4[:,1]\n",
    "tooltips[0] = (\"(x,y)\",  \"(@x4,@y4)\")\n",
    "# gray boxes around good-bad (fake) drag'n'drop \"category\"\n",
    "gb = np.vstack([emb4[good10,], emb4[bad10,]])\n",
    "gbsource.data[\"x4\"] = gb[:,0]\n",
    "gbsource.data[\"y4\"] = gb[:,1]\n",
    "\n",
    "p4 = figure(title=\"Iris UMAP post drag'n'drop\",\n",
    "            tooltips=tooltips)\n",
    "circles = p4.circle( source=source, x=\"x4\", y=\"y4\",\n",
    "    size=8, fill_alpha=0.5,\n",
    "    color={\"field\": \"label\", \"transform\": cmap},\n",
    "    legend_group=\"label\"\n",
    ")\n",
    "hover = p4.select_one(HoverTool)\n",
    "hover.renderers = [circles]\n",
    "p4.square(source=gbsource, x=\"x4\", y=\"y4\",\n",
    "          size=16, line_alpha=0.7, line_width=4, fill_alpha=0.0,\n",
    "          color={\"field\": \"label\", \"transform\": cmap},\n",
    "          legend_group=\"label\"\n",
    ")\n",
    "p4.legend.location = 'center_center'\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "#show(p4)\n",
    "#output_file(\"iris4.html\")\n",
    "show(column(p1,p2,p4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now pin and embed **into 3-D**\n",
    "Initialization:\n",
    "\n",
    "- new *x*-axis for \"user dimension\"\n",
    "- old *xy* data plopped into new *yz* dimensions, at x=0\n",
    "\n",
    "UMAP-constraints pins 6 points at user-dimension *x* values $\\pm 10$,\n",
    "leaving *yz* free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinned UMAP (and undo UMAP internal rescaling)\n",
    "#   We take emb2 (rotated so good/bad kinda' match old 'x' axis)\n",
    "#   and re-embed into 3-D.  This is where umap starts from.\n",
    "emb5 = np.ndarray((emb2.shape[0],3), dtype=np.float32)\n",
    "# Out new axis will become 'x'; old x-y are moved to y-z\n",
    "emb5[:,0] = 0.0        # new 'x'\n",
    "emb5[:,1] = emb2[:,0]  # old 'x' --> new 'y'\n",
    "emb5[:,2] = emb2[:,1]  # old 'y' --> new 'z'\n",
    "# pin a few points on new 'x'\n",
    "emb5[good10,0] = -10\n",
    "emb5[bad10,0]  = +10\n",
    "print(\"emb5.shape\",emb5.shape)\n",
    "print(\"good10:\\n\", emb5[good10,])\n",
    "print(\"bad10:\\n\",  emb5[bad10,])# re-embed just with new init conditions\n",
    "pin_mask = np.ones(emb5.shape, dtype=np.float32) # todo: allow float32\n",
    "pin_mask[good10,0] = 0.0 # zero gradient, so zero 'x' movement of init embedding\n",
    "pin_mask[bad10,0] = 0.0  # new y-z are unconstrained\n",
    "print(\"type(pin_mask)\",type(pin_mask), isinstance(pin_mask, np.ndarray))\n",
    "for i in range(pin_mask.shape[0]):\n",
    "    if np.any(pin_mask[i,] == 0.0):\n",
    "        print(\"pinned sample\",i,\"pin_mask\",pin_mask[i,],\"emb3\",emb3[i,])\n",
    "print(\"pin_mask.shape\",pin_mask.shape)\n",
    "print(\"pin_mask good10:\\n\", pin_mask[good10,])\n",
    "print(\"pin_mask bad10:\\n\",  pin_mask[bad10,])# re-embed just with new init conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"init=emb5 good10:\\n\", emb3[good10,])\n",
    "print(\"init=emb5 bad10:\\n\",  emb3[bad10,])# re-embed just with new init conditions\n",
    "print(emb5[10:15,])\n",
    "print(\"emb5.shape\",emb5.shape)\n",
    "print(\"pin_mask.shape\",pin_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedder5 = umap.UMAP( n_components=3,\n",
    "    n_neighbors=50, learning_rate=0.5, random_state=init_random_state, init=emb5,\n",
    "    negative_sample_rate=5, repulsion_strength=0.40,\n",
    "    min_dist=0.001, spread=3.0,\n",
    "    #output_constrain = # may want a 3-D box [-10,+10] constraint on all 3 lo dims?\n",
    "    #a=0.1, b=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time emb6 = embedder5.fit_transform(iris.data, data_constrain=pin_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pinned umap emb6 good10:\\n\", emb6[good10,])\n",
    "print(\"pinned umap emb6 bad10:\\n\",  emb6[bad10,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipyvolume and jupyter is BRITTLE (\"Error displaying widget\")\n",
    "#import ipyvolume as ipv\n",
    "#import numpy as np\n",
    "#N = 1000\n",
    "#x, y, z = np.random.normal(0, 1, (3, N))\n",
    "#fig = ipv.figure()\n",
    "#scatter = ipv.scatter(x, y, z)\n",
    "#ipv.show()\n",
    "# Hmm.  I don't see any points (ipyvolume=0.6.0a8)\n",
    "#import ipyvolume as ipv\n",
    "#emb6 *= 0.01\n",
    "#x,y,z = (emb6[:,0], emb6[:,1], emb6[:,2])\n",
    "#scatter = ipv.scatter(x,y,z)\n",
    "#ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input (pins) as a new dimension\n",
    "Here the hi-D (4-D only in this simplistic case) connectivity\n",
    "is mapped into 3-D, where *x* becomes a **user axis**.\n",
    "\n",
    "Original all data then lie on *yz* plane, with x=0.0 because we\n",
    "have no user information.  After pulling 3 points to x=-10.0 and\n",
    "another 3 to x=+10.0, the whole point cloud readjusts in 3-D.\n",
    "\n",
    "Out pins **do** align somewhat with an existing feature, so this\n",
    "kinda' works nicely.  In fact, a PCA of crushing *yz* to a single\n",
    "axis gives a plot fairly similar to emb4\n",
    "\"UMAP-constraints directly to 2-D\".\n",
    "\n",
    "### extensions (TBD)\n",
    "This may not be the case if we have some higher dimensional data and the\n",
    "user features have no (or strange) relation to existing ones.  In this\n",
    "case you can't get around *learning* a new user-centric feature.\n",
    "In hard cases, this might even require going back to raw data.\n",
    "\n",
    "Hi-D UMAP supports a wide variety of distance metrics.\n",
    "\n",
    "The first UMAP-constraints only have examples for lo-D begin Euclidean.\n",
    "Support for non-Euclidean lo-D is not yet implemented (need a simple\n",
    "demo as those code paths get populated).\n",
    "\n",
    "At this time, I see hyperbolic lo-D coords as the main alternative to Euclidean.\n",
    "\n",
    "UMAP-constraints has operating modes where 'head != tail' for which how the\n",
    "constraints operate may need more careful consideration\n",
    "\n",
    "### failure: confounding hi-D \"noise\" dimensions\n",
    "We see several *irrelevant* dimensions are moving *virginica* to the *bad* side.\n",
    "They actually have *sepal length* low, and should be on r.h.s.\n",
    "\n",
    "The analysis **COULD** be determining a better hi-D metric.  Since our pins were based on sepal length, a *weighted Euclidean* hi-D metric could improve things.\n",
    "\n",
    "- In more general cases, training a new user-class predictor might be warranted.\n",
    "- Or worse, training a new hi-D feature from rawer data may be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mpcolors\n",
    "#fig, (ax,bx) = plt.subplots(nrows=1, ncols=2, figsize=(24, 12),\n",
    "#    subplot_kw={'projection': '3d'})\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "# 3-D projection axes\n",
    "ax = plt.axes(projection='3d')\n",
    "# defined axes\n",
    "x,y,z = (emb6[:,0], emb6[:,1], emb6[:,2])\n",
    "#c = iris.data[:,0]\n",
    "s = np.full((x.shape[0]), 80); s[good10] = 200; s[bad10] = 200\n",
    "#s = 80\n",
    "c = 0.25 * (iris.target + (x+10.)*0.02)\n",
    "ec = mpl.cm.viridis(c)\n",
    "ec[good10,:] = [0.,0.,0.,1.]\n",
    "ec[bad10,:]  = [0.,0.,0.,1.]\n",
    "ax.scatter(x,y,z,s=s, c=c,norm=mpl.colors.Normalize(0.0,1.0),\n",
    "           edgecolor=ec, linewidth=3)\n",
    "#plot\n",
    "ax.set_title('new x-axis for user-pinned points')\n",
    "ax.set_xlabel('X: User Interest')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.show()\n",
    "#\n",
    "# for comparison, let's look at the original 2-D UMAP in same coordinates\n",
    "# (before pulling user points off x=0)\n",
    "#\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "x,y,z = (np.zeros_like(emb4[:,0]), emb4[:,0], emb4[:,1])\n",
    "bx = plt.axes(projection='3d')\n",
    "bx.scatter(x,y,z,s=s, c=c,norm=mpl.colors.Normalize(0.0,1.0),\n",
    "           edgecolor=ec, linewidth=3)\n",
    "#plot\n",
    "bx.set_title('original pre-pull 2-D point cloud')\n",
    "bx.set_xlabel('X: User Interest')\n",
    "bx.set_ylabel('Y Label')\n",
    "bx.set_zlabel('Z Label')\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Next: How to \"simply\" project yz onto single axis (pca for yz)\n",
    "yz = emb6[:,1:3]\n",
    "print(\"yz\",yz[10:15,:])\n",
    "print(\"emb2\",emb2[10:15,:])\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1, whiten=True)\n",
    "pca.fit(yz)\n",
    "#Project the data in 2D\n",
    "%time y_pca = pca.transform(yz)\n",
    "print(\"y_pca\",y_pca.shape,\"\\n\",y_pca[10:15])\n",
    "emb7 = np.zeros_like(emb2)\n",
    "emb7[:,0] = emb6[:,0]\n",
    "emb7[:,1] = y_pca[:,0]\n",
    "print(\"emb7\",emb7[10:15,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.data[\"x7\"] = emb7[:,0]\n",
    "source.data[\"y7\"] = emb7[:,1]\n",
    "source.data[\"user\"] = iris.data[:,0] # first feature, sepal length, used for pins\n",
    "tooltips[0] = (\"(x,y)\",  \"(@x4,@y4)\")\n",
    "# gray boxes around good-bad (fake) drag'n'drop \"category\"\n",
    "gb = np.vstack([emb7[good10,], emb7[bad10,]])\n",
    "gbsource.data[\"x7\"] = gb[:,0]\n",
    "gbsource.data[\"y7\"] = gb[:,1]\n",
    "\n",
    "p7 = figure(title=\"Iris UMAP --> 3D --pca--> 2D\",\n",
    "            tooltips=tooltips)\n",
    "#mycmap = linear_cmap(field_name='user', palette='Viridis256',\n",
    "#                     low=min(iris.data[:,0]) ,high=max(iris.data[:,0]))\n",
    "circles = p7.circle( source=source, x=\"x7\", y=\"y7\",\n",
    "    size=8, fill_alpha=0.5,\n",
    "    color={\"field\": \"label\", \"transform\": cmap},\n",
    "    #color=mycmap, # {\"field\": \"user\", \"transform\": mycmap},\n",
    "    legend_group=\"label\"\n",
    ")\n",
    "hover = p7.select_one(HoverTool)\n",
    "hover.renderers = [circles]\n",
    "p7.square(source=gbsource, x=\"x7\", y=\"y7\",\n",
    "          size=16, line_alpha=0.7, line_width=4, fill_alpha=0.0,\n",
    "          color={\"field\": \"label\", \"transform\": cmap},\n",
    "          legend_group=\"label\"\n",
    ")\n",
    "p7.legend.location = 'center_center'\n",
    "\n",
    "output_notebook()\n",
    "show(p7)\n",
    "output_file(\"iris4.html\")\n",
    "#show(gridplot([[p1,p2],[p4,p7]]))\n",
    "\n",
    "iris_grid = gridplot([[p1,p2],[p4,p7]],\n",
    "                     toolbar_location=None, #sizing_mode='stretch_width'\n",
    "                    )\n",
    "show(iris_grid)\n",
    "\n",
    "# This did NOT work out... needed 'selenium' and then err about not running in chrome??\n",
    "#iris_grid.width = 1024\n",
    "#export_png(iris_grid, filename=\"/tmp/iris_grid.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### umap.utils.reposition\n",
    "- Q: If you've a decent `init=` but add a repositioning constraint,\n",
    "  can you get a probably-better `init=` fairly cheaply?\n",
    "- A: Quick'n'dirty *manual* repositioning of certain selected points,\n",
    "  with some 1st-nearest-neighbor drag.\n",
    "#### def reposition(x, up_pts, up_pos, umapper, thresh=0.0, verbose=0, nnfactor=1.0):\n",
    "```\n",
    "    python wrapper for the reposition_jit.\n",
    "\n",
    "    Arguments  (arrays are numpy arrays)\n",
    "    ---------\n",
    "\n",
    "    x       data array[pts,dim] ~ a lo-D embedding\n",
    "    up_pts  int vector which pts (rows of x) explicitly move?\n",
    "    up_pos  array[len(up_pts), dim] ~ final destination of those points.\n",
    "    umapper umapper.graph_ is a csr-format compressed array of membership strengths in [0,1]\n",
    "    thresh  skip this quantile of weakest connection STRENGTHs (skip far/weak nbrs)\n",
    "            effectively cuts down on umapper.n_neighbors.\n",
    "            [default 0.0] uses full umapper weight matrix nn.s\n",
    "            (i.e. roughly umapper.n_neighbors*(1-thresh) nn.s will move\n",
    "                  w/ some variation due to symmetrization)\n",
    "    verbose 0,1,2,3 effective\n",
    "    nnfactor [default 1.0] reduce n.n. movement strengths by this factor\n",
    "\n",
    "    at high thresh, up_pts neighborhoods are more likely disjoint\n",
    "    at default, up_pts may have 'other' nbrs that accumulate a weighted\n",
    "                average of up_pts movement deltas.  weights are taken\n",
    "                directly from the umapper.graph_.\n",
    "                Weighted average movement deltas are multiplied by some\n",
    "                nnfactor [default 1.0]\n",
    "```\n",
    "reposition_jit additionally explains:\n",
    "```\n",
    "    Return      \n",
    "    ------\n",
    "    a new low-D embedding based on x[:,:] and its explicit updates 'up_*'\n",
    "        \n",
    "    Particularly for lo-D == 2, neighbors can easily get \"stuck\" behind other points.\n",
    "    The returned embedding can \"spread out\" a cluster based on just a few points.\n",
    "        \n",
    "    If x is a current UMAP lo-D embedding, the `reposition` return value might\n",
    "    be a better starting point to continue (modify) an existing umap embedding.\n",
    "                \n",
    "    NOTES/TODO:\n",
    "        - option to adjust thresh so NO neighborhoods intersect, so points\n",
    "          move either one way or the other and never in some average direction\n",
    "        - thresh==0.0 and nnfactor==1.0 might not be good defaults.\n",
    "        - Also umapper.n_neighbors roughly influences how many points comprise\n",
    "          each neighborhood, so again might influence a good value for thresh.\n",
    "        - given the expanded movements, \"alignment\" with previous embedding becomes\n",
    "          less meaningful.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if \"reposition\" in dir(umap.utils):\n",
    "    #\n",
    "    # OK. I'm changing thresh from an absolute strength to a fractional\n",
    "    #     reduction in NUMBER of n.n. whose strengths are in the umap\n",
    "    #     weight matrix.\n",
    "    # i.e. if umapper.n_neighbor is 50 and thresh=0.5,\n",
    "    #      then only the strongest(nearest) 25 connections get pulled\n",
    "    a = np.array([0, 1, 4, 5, 6, 8, 9, 11, 23, 50], dtype=np.float32)\n",
    "    # half of these are <= 6, and half are >= 8,\n",
    "    # so expect q=0.5 to output 7\n",
    "    for q in [0., .1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0]:\n",
    "        x = np.quantile(a, q)        # numba-supported simple call\n",
    "        print(f\"{q=:.2f} --> np.quantile(a,{q:.2f})={x:.2f}\")\n",
    "        if q==0.5:\n",
    "            assert x==7.0\n",
    "    \n",
    "    # This init-helper was added to github kruus umap branch constraints\n",
    "    #\n",
    "    # Now try the 'reposition' on emb2 (6 picked points w/ best rotation)\n",
    "    #help(\"umap.utils.reposition\")\n",
    "    #recall:\n",
    "    #emb2 pinning init good10:\n",
    "    #[[  6.47720251 -12.11776187]\n",
    "    #[ -6.29080699   5.5100111 ]\n",
    "    #[ -4.66873046   6.60774872]]\n",
    "    #emb2 pinning init bad10:\n",
    "    #[[  2.46912696 -13.00592535]\n",
    "    #[ -1.300408     5.2159056 ]\n",
    "    #[  3.31361343   7.7900176 ]]\n",
    "    # emb3[good10,0] = -10\n",
    "    # emb3[bad10,0]  = +10\n",
    "    print(\"drag'n'drop reposition (long-hand)\")\n",
    "    pts = emb2.copy()\n",
    "    print(f\"{good10=} x-coord --> -10.0\")\n",
    "    print(f\"{bad10=} x-coord --> +10.0\")\n",
    "    up_pts = np.concatenate((good10,bad10))\n",
    "    up_pos = pts[up_pts,:]\n",
    "    print(f\"{up_pts=}\")\n",
    "    print(f\"init {up_pos=}\")\n",
    "    up_pos[0:3,0] = -10.0\n",
    "    up_pos[3:6,0] = +10.0\n",
    "    print(f\"final {up_pos=}\")\n",
    "    \n",
    "    #emb2_title=(\"emb2 should be const! Iris \"+method_names[method]+\" drag'n'drop init, emb2\")\n",
    "    #p2 = plot_emb(emb2,emb2_title)\n",
    "    #show(p2)\n",
    "    \n",
    "    # drag'n'drop (no n.n. pulling) --> emb2a\n",
    "    emb2a = emb2.copy()\n",
    "    emb2a[good10,0] = -10.0\n",
    "    emb2a[bad10,0] = +10.0\n",
    "    \n",
    "    # reposition \"n.n. connection strengths\" come from an existing UMAP._graph\n",
    "    umapper = umapper50 # an initial one, n_neighbors=50\n",
    "    umapper = embedder3 # a later one (equiv?)\n",
    "    \n",
    "    emb2b = umap.utils.reposition(emb2, up_pts, up_pos, umapper, thresh=0.0, verbose=0, nnfactor=1.0 )\n",
    "    emb2c = umap.utils.reposition(emb2, up_pts, up_pos, umapper, thresh=0.0, verbose=0, nnfactor=0.75 )\n",
    "    emb2d = umap.utils.reposition(emb2, up_pts, up_pos, umapper, thresh=0.75, verbose=0, nnfactor=0.75 )\n",
    "    print(f\"\\ninit {emb2[up_pts,]=}\")\n",
    "    print(f\"drag only (no n.n. pulling) {emb2a[up_pts,]=}\")\n",
    "    print(f\"now reposition ~ drag + n.n. pulls.  We are not running umap.\")\n",
    "    print(f\"reposition emb2b [default] {emb2b[up_pts,]=}\")\n",
    "    print(f\"reposition emb2c [default] {emb2c[up_pts,]=}\")\n",
    "    print(f\"reposition emb2d [default] {emb2d[up_pts,]=}\")\n",
    "    \n",
    "    emb2_title=(\"emb2: Iris \"+method_names[method]+\" drag'n'drop init, emb2\")\n",
    "    p2 = plot_emb(emb2,emb2_title)\n",
    "    #show(p2)\n",
    "    \n",
    "    p2a = plot_emb(emb2a, f\"drag'n'drop user moved 6 points emb2a\") # emb2, raw drag'n'drop\n",
    "    p2b = plot_emb(emb2b, f\"drag'n'drop + reposition[default args] nn={umapper.n_neighbors} emb2b\")\n",
    "    p2c = plot_emb(emb2c, f\"drag'n'drop + reposition emb2c nn={umapper.n_neighbors} nnfactor=0.75\")\n",
    "    p2d = plot_emb(emb2d, f\"drag'n'drop + reposition emb2d nn={umapper.n_neighbors} nnfactor=0.75, thresh 0.75\")\n",
    "    print(\"Interpretation:\")\n",
    "    print(\"   p2d, (thresh 0.75) for each drag'n'drop point, moves 1/4 of the nn.s,\")\n",
    "    print(\"   with 3/4 of the umap connection strength, toward the drop position\")\n",
    "    print(\"   So you might see 3 clusters after repositioning\")\n",
    "    repo_grid = gridplot([[p2,None],[p2a,p2b],[p2c,p2d]], toolbar_location=None)\n",
    "    show(repo_grid)\n",
    "    #show(p2a)\n",
    "    #show(p2b)\n",
    "    \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo a user-clustering of the 3 \"good\" pts\n",
    "This uses a NEW `umap.constrain_clust.mk_constrain_ipts(idx,pts,...)` constraint function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: demo clustering via simple weight-matrix adjustment\n",
    "# i.e. all cluster members have all-to-all weight-matrix (wm) set at strength=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "from umap.constrain_clust import mk_clustering_pts, mk_clustering_ipts\n",
    "#import umap.constraints as con\n",
    "\n",
    "#\n",
    "# ------- Inputs (python) -----------------------------\n",
    "n_samples = iris.data.shape[0]\n",
    "cluster_lists = [good10, bad10]\n",
    "springs = np.array([0.9,0.9], dtype=np.float32)\n",
    "lr = 0.5   # learning rate (gradient multiplier) for spring forces\n",
    "\n",
    "emb8 = emb2.copy()\n",
    "emb8= np.array(emb8, dtype=np.float32 )    # Uggh. For now 'reposition' specifies float32\n",
    "\n",
    "mindist = 1.0\n",
    "\n",
    "print(f\"Inputs:\\n {n_samples=}\")\n",
    "print(f\" good,bad {cluster_lists=}\")\n",
    "print(f\" {springs=} {lr=} {mindist=}\")\n",
    "print(f\" {emb8.shape=}\\n\")\n",
    "\n",
    "#\n",
    "# ------------- what's begin clustered? ---------------\n",
    "init_centroids = []\n",
    "for cl, cl_idxs in enumerate(cluster_lists):\n",
    "    print(f\"cluster {cl} cl_pts {list(cl_idxs.data)}\")\n",
    "    cl_pts = emb8[cl_idxs]\n",
    "    print(f\"  {cl_pts=}\")\n",
    "    \n",
    "    #cl_avg = np.mean(cl_pts, axis=1)\n",
    "    # equiv.\n",
    "    cl_avg = umap.constrain_clust.np_mean_axis_0(cl_pts)\n",
    "    print(f\"  {cl_avg=}\")\n",
    "    init_centroids.append(cl_avg)\n",
    "print(\"\")\n",
    "\n",
    "# for manual reposition, just need list of all pts moved, and their\n",
    "# respective (repeated) cluster centroids\n",
    "up_pts = np.concatenate((cluster_lists[0], cluster_lists[1]))\n",
    "print(f\"{up_pts=}\")\n",
    "up_pos = np.vstack( (emb8[cluster_lists[0],:], emb8[cluster_lists[1],:]) )\n",
    "print(f\"init {up_pos=}\")\n",
    "g = len(good10)\n",
    "b = len(bad10)\n",
    "up_pos[0:g,:]     = init_centroids[0].reshape(1,-1).repeat(g,axis=0)\n",
    "up_pos[g:(g+b),:] = init_centroids[1].reshape(1,-1).repeat(b,axis=0)\n",
    "print(f\"final {up_pos=}\")\n",
    "#np.reshape(\n",
    "\n",
    "#\n",
    "# ------------ create & call jit constraint -----------\n",
    "# Now that we have the python-ish inputs set up,\n",
    "# create a jit constraint function of simplified signature\n",
    "#\n",
    "clusterer_ipts = mk_clustering_ipts(0, pts, cluster_lists, springs, lr=lr, mindist=mindist)\n",
    "# This clusterer makes clusters, but the cluster centroids are free-floating.\n",
    "#\n",
    "# TODO:\n",
    "# investigate ways to additionally force whole-cluster, to (say) right/left of plot.\n",
    "\n",
    "# You COULD \"just run\" the constraint as:\n",
    "#clusterer_ipts(idx, pts)  # simplified call signature, other args are now mkdo_ipts locals\n",
    "\n",
    "data_constraints = { 'idx_ipts': clusterer_ipts }\n",
    "print(f\"{data_constraints=}\")\n",
    "\n",
    "def mk_bound_y_values(lo, hi):\n",
    "    bound_los = np.array([+999.,lo], dtype=np.float32)\n",
    "    bound_his = np.array([-999.,hi], dtype=np.float32)\n",
    "    @numba.njit()\n",
    "    def bound_y_values(pt):\n",
    "        return umap.constraints.dimlohi_pt(pt, bound_los, bound_his)\n",
    "    # this function does NOT depend on 'idx' arg\n",
    "    return bound_y_values\n",
    "y_bounder = mk_bound_y_values(-5.0,+5.0)\n",
    "\n",
    "print(\"Specify 'init' embedding for umapper2\")\n",
    "print(\"  output_constrain['pt'] = y_bounder\")\n",
    "print(\"  data_constrain['ipts'] = clusterer_ipts\")\n",
    "umapper8 = umap.UMAP(\n",
    "    n_neighbors=10, learning_rate=0.1, random_state=12346, min_dist=0.001,\n",
    "    #output_constrain = { 'pt': y_bounder }, # any pt, ind't of dataset\n",
    "    init=emb8, n_epochs=1,\n",
    ")\n",
    "\n",
    "p2 = plot_emb(emb2, \"init=emb2\")\n",
    "\n",
    "# unfortunately, we need umapper8.graph_ BEFORE manual repositioning\n",
    "# Note that n_epochs=1 actually does nothing, but we now have a umapper8.graph_\n",
    "# so we can do a \"manual reposition\"\n",
    "emb8b = umapper8.fit_transform(iris.data,\n",
    "                               data_constrain={'idx_ipts': clusterer_ipts},\n",
    "                              )\n",
    "print(f\"{type(emb8)=} {emb8.dtype=} {emb8.shape=}\",flush=True)\n",
    "emb8r = umap.utils.reposition(emb8,  up_pts, up_pos, umapper8, thresh=0.8, verbose=4, nnfactor=0.5 )\n",
    "\n",
    "# just more epochs\n",
    "umapper8.n_epochs = 20\n",
    "emb8c = umapper8.fit_transform(iris.data, data_constrain={'idx_ipts': clusterer_ipts})\n",
    "# cf. reposition + epochs\n",
    "umapper8.embedding = emb8r\n",
    "umapper8.n_epochs = 20\n",
    "emb8d = umapper8.fit_transform(iris.data, data_constrain={'idx_ipts': clusterer_ipts})\n",
    "\n",
    "p8 = plot_emb(emb8, \"init=emb8\")\n",
    "p8r = plot_emb(emb8r, \"utils.reposition\")\n",
    "p8b = plot_emb(emb8b, \"clusterer\") # + y_bounder(-5,+5)\")\n",
    "p8c = plot_emb(emb8c, f\"clusterer ({umapper8.n_epochs} more epochs)\")\n",
    "p8d = plot_emb(emb8d, f\"reposition+clusterer ({umapper8.n_epochs} more epochs)\")\n",
    "repo_grid = gridplot([[p2,p8],[p8b,p8r],[p8c,p8d]], toolbar_location=None)\n",
    "show(repo_grid)\n",
    "\n",
    "print(\"\\nNew clusters emb8d (reposition+4 more epochs):\")\n",
    "for cl, cl_idxs in enumerate(cluster_lists):\n",
    "    print(f\"cluster {cl} cl_pts {list(cl_idxs.data)}\")\n",
    "    cl_pts = emb8d[cl_idxs]\n",
    "    print(f\"  {cl_pts=}\")\n",
    "    cl_avg = np.mean(cl_pts, axis=1)\n",
    "    print(f\"  {cl_avg=}\")\n",
    "\n",
    "print(\"Played around a bunch, but no big success\")\n",
    "print(\"The clusterer does NOT pull n.n. of cluster members hard enough!\")\n",
    "print(\"However manual repositioning can even be too strong unless tuned\")\n",
    "print(\"Perhaps also(?) set wm strength=1 edges between ALL cluster members!\")\n",
    "    \n",
    "#\n",
    "# ------------- output --------------------------------\n",
    "# check we got the same \"output\" (in-place modification of our pts array)\n",
    "#\n",
    "\n",
    "print(\"Goodbye!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "How can umap layout pull clusterer nn.s more?  \n",
    "\n",
    "One way might keep same dims, but increase the `graph_` edge weights\n",
    "of cluster-nn.s by some factor (ex. 10x)\n",
    "\n",
    "`reposition` kinda' adjusts using existing n.n. weights, but the subsequent\n",
    "umap embed destroys this.  \n",
    "\n",
    "When umap embeds, perhaps existing edges are much more frequently updated\n",
    "so the clustered pts seem not to drag their nn.s much at all !\n",
    "\n",
    "Another way is to re-embed the original iris.data in some additional hi-D\n",
    "\"clustering dims\".  Now the umap graph will be recalculated, but still we\n",
    "risk not \"propagating\" our *clustering belief* strongly enough to nn.s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test code (throwaway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2]\n",
    "print(len(a))\n",
    "b=np.array([[1.0, np.inf], [np.inf, np.inf]])\n",
    "print(np.sum(a==np.inf), np.sum(b == np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import os\n",
    "print(numba.typeof(None))\n",
    "#\n",
    "# uncomment next line to see:\n",
    "#   The 'is not None' does not seem to get elided by numba\n",
    "#os.environ.setdefault('NUMBA_DEBUG','1')\n",
    "#\n",
    "#@numba.njit((numba.types.int32,numba.types.optional(numba.types.int32)))\n",
    "#\n",
    "# this generates foo...Eii...   and foo...Eiv... funcs, but both seem complicated\n",
    "#\n",
    "# in some numba version this vomits about 'isinstance'\n",
    "# detecting None seems somewhat fragile :(\n",
    "#\n",
    "#@numba.njit([\"int32(int32,none)\", \"int32(int32,int32)\"])\n",
    "#def foo(a,b):\n",
    "#    \"\"\" Return a+=b, if b is not None \"\"\"\n",
    "#    if isinstance(b,numba.types.NoneType):\n",
    "#        a += b\n",
    "#    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numba now seems to have trouble with isinstance\")\n",
    "if False:\n",
    "    @numba.njit([\"int32(int32,int32)\", \"int32(int32,bool)\"])\n",
    "    def foo2(a,b):\n",
    "        \"\"\" Return a+=b, if b is not None \"\"\"\n",
    "        if not isinstance(b,bool):\n",
    "            a += b\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(fastmath=True, parallel=False)\n",
    "def bar(a,bb):\n",
    "    \"\"\" Return a+=b, if b is not None \"\"\"\n",
    "    if bb is not None:\n",
    "        a += bb\n",
    "    return a\n",
    "#op0 = numba.njit( foo, fastmath=True, parallel=False) # NEED signature\n",
    "#op0 = numba.njit( bar, signature=(numba.types.int32, numba.types.none), fastmath=True, parallel=False) # NEED signature\n",
    "#op0.inspect_types(pretty=True)\n",
    "print(bar(4,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bar(4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=[]\n",
    "for i in range(5):\n",
    "    idxs.append(i)\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
